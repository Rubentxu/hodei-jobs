# Arquitectura del Sistema

**VersiÃ³n**: 8.0
**Ãšltima ActualizaciÃ³n**: 2025-12-18

## Domain-Driven Design (DDD)

El proyecto sigue una arquitectura DDD hexagonal con las siguientes capas:

```mermaid
graph TB
    subgraph "Presentation Layer Adapters"
        CLI[CLI]
        REST[REST API Axum]
        GRPC[gRPC Services]
        WORKER[Worker Agent]
    end

    subgraph "Application Layer"
        UC1[Job Execution Use Cases]
        UC2[Provider Registry]
        UC3[Worker Lifecycle Manager]
        UC4[Smart Scheduler]
        UC5[Job Controller]
        UC6[Worker Provisioning]
    end

    subgraph "Domain Layer"
        subgraph "Job Execution Context"
            JOB[Job Aggregate]
            SPEC[JobSpec + CommandType]
            QUEUE[JobQueue]
            TEMPLATE[JobTemplate]
        end

        subgraph "Worker Management Context"
            WORKER_DOM[Worker Aggregate]
            WPROV[WorkerProvider Trait]
            WREG[WorkerRegistry]
        end

        subgraph "Provider Context"
            PROV[ProviderConfig]
            CAP[ProviderCapabilities]
        end

        subgraph "Shared Kernel"
            ID[WorkerId, JobId, ProviderId]
            STATE[WorkerState, JobState]
            ERR[DomainError, ProviderError]
            OTP[OtpTokenStore]
        end
    end

    subgraph "Infrastructure Layer"
        DOCKER[DockerProvider]
        K8S[KubernetesProvider]
        FC[FirecrackerProvider]
        PG[(Postgres)]
        REPO[Repositories sqlx]
        LOGS[LogStreamService]
    end

    CLI --> UC1
    REST --> UC1
    REST --> UC2
    GRPC --> UC2
    WORKER --> GRPC

    UC1 --> JOB
    UC2 --> PROV
    UC3 --> WORKER_DOM
    UC4 --> WREG
    UC5 --> QUEUE
    UC6 --> WPROV

    JOB --> ID
    WORKER_DOM --> STATE
    WPROV --> DOCKER
    WPROV --> K8S
    WPROV --> FC

    WREG --> REPO
    UC1 --> LOGS
    REPO --> PG
```

## Worker Agent - Optimizaciones v8.0

### LogBatching & Backpressure (T1.1-T1.5)

El worker agent implementa un sistema de batching de logs para reducir significativamente la sobrecarga de red:

```mermaid
graph TD
    A[LogEntry generada] --> B{Buffer lleno?}
    B -->|No| C[Agregar a buffer]
    B -->|SÃ­| D[Flush LogBatch]
    D --> E[Enviar LogBatch vÃ­a gRPC]
    E --> F[Reset buffer]
    C --> G[Timer flush interval]
    G --> H{Timeout?}
    H -->|SÃ­| D
    H -->|No| I[Aguardar]
    I --> G

    J[ServerMessage] --> K[try_send()?]
    K -->|Full| L[Drop message<br/>Backpressure]
    K -->|OK| M[Continuar]
```

**Beneficios:**
- **90-99% reducciÃ³n** en llamadas gRPC (de lÃ­nea por lÃ­nea a batches)
- **Backpressure handling** con `try_send()` para evitar bloqueos
- **Flush automÃ¡tico** por capacidad o intervalo de tiempo
- **Thread-safe** usando `Arc<Mutex<LogBatcher>>`

### Write-Execute Pattern (T1.6-T1.7)

PatrÃ³n robusto de ejecuciÃ³n de scripts inspirado en Jenkins/K8s:

```mermaid
flowchart TD
    A[Recibir RunJobCommand] --> B[Crear archivo temporal]
    B --> C[Escribir script + safety headers]
    C --> D[Hacer archivo ejecutable]
    D --> E[Ejecutar con Command]
    E --> F[Stream logs en tiempo real]
    F --> G[Enviar JobResult]
    G --> H[Limpiar archivo temporal<br/>async con tokio::spawn]

    subgraph "Safety Headers"
        I[set -e<br/>exit on error]
        J[set -u<br/>undefined variables error]
        K[set -o pipefail<br/>pipe failure detection]
    end

    C --> I
    C --> J
    C --> K
```

**CaracterÃ­sticas:**
- InyecciÃ³n automÃ¡tica de safety headers (`set -euo pipefail`)
- GestiÃ³n segura de archivos temporales
- Cleanup asÃ­ncrono no bloqueante
- EjecuciÃ³n robusta con manejo de errores

### Secret Injection (T2.1-T2.3)

InyecciÃ³n segura de secretos via stdin:

```mermaid
sequenceDiagram
    participant W as Worker
    participant E as JobExecutor

    W->>E: execute_script(script, env, secrets)
    E->>E: Serializar secrets a JSON
    E->>E: stdin.write_all(&json)
    E->>E: stdin.shutdown() [Write]
    E->>Command: spawn()
    Command->>Command: Leer secrets desde stdin
    Command->>Command: Ejecutar script con env
    Note over E,Command: Stdin cerrado despuÃ©s<br/>de inyecciÃ³n - seguridad
```

**Seguridad:**
- Secrets nunca aparecen en logs (redacciÃ³n automÃ¡tica)
- TransmisiÃ³n via stdin con cierre inmediato
- JSON serializado para mÃºltiples secretos
- AuditorÃ­a de acceso a secretos

### Zero-Copy I/O (T3.1-T3.2)

OptimizaciÃ³n de lectura de logs:

```rust
// FramedRead + BytesCodec para zero-copy
let mut framed = FramedRead::new(source, BytesCodec::new());
while let Some(chunk) = framed.next().await {
    // Direct Bytes slice - no copy
    let bytes = chunk?;
    // Process directly from Bytes
}
```

**Beneficios:**
- **Zero-copy** de datos de log
- **BytesCodec** para decodificaciÃ³n eficiente
- **FramedRead** para manejo de lÃ­mites
- ReducciÃ³n de allocaciones de memoria

### MÃ©tricas AsÃ­ncronas (T3.3-T3.5)

Sistema de mÃ©tricas con cache TTL:

```mermaid
graph LR
    A[MÃ©tricas Request] --> B{Cache vÃ¡lido?}
    B -->|SÃ­| C[Return cached]
    B -->|No| D[Spawn blocking task]
    D --> E[Recolectar desde cgroups]
    E --> F[Update cache + timestamp]
    F --> G[Return fresh metrics]
    G --> H[Background update]

    subgraph "Cache TTL"
        I[35 segundos TTL]
        J[Instant timestamp]
        K[Atomic update]
    end

    F --> I
```

**CaracterÃ­sticas:**
- **Cache TTL** de 35 segundos
- **spawn_blocking** para tareas intensivas
- **yield_now** para permitir preemption
- IntegraciÃ³n cgroups para containers

### mTLS Infrastructure (T4.1-T4.5)

Infraestructura completa de mTLS para Zero Trust:

```mermaid
graph TD
    A[CertificatePaths] --> B[Load certs]
    B --> C[ServerTlsSettings]
    C --> D[CertificateExpiration checker]

    subgraph "PKI Infrastructure"
        E[CA Root Certificate]
        F[Server Certificate]
        G[Client Certificate]
        H[Certificate Revocation]
    end

    subgraph "Certificate Management"
        I[Auto-rotation]
        J[Validity tracking]
        K[Expiration alerts]
    end

    E --> F
    E --> G
    D --> I
    D --> J
    D --> K

    script[scripts/generate-certificates.sh]
    doc1[docs/security/PKI-DESIGN.md]
    doc2[docs/security/CERTIFICATE-MANAGEMENT.md]

    script --> E
    doc1 --> E
    doc2 --> E
```

**Nota:** Requiere upgrade a `tonic >= 0.15` para habilitar TLS features.

## ComunicaciÃ³n Server â†” Worker Agent (PRD v8.0)

```mermaid
sequenceDiagram
    participant P as Provider (Docker)
    participant S as Server
    participant W as Worker Agent

    Note over P,W: 1. Provisioning
    S->>P: create_worker(WorkerSpec)
    P->>P: Start container with OTP token
    P-->>S: WorkerHandle + OTP

    Note over S,W: 2. Registration (OTP Auth)
    W->>S: Register(auth_token=OTP, worker_info)
    S->>S: validate_otp(token)
    S-->>W: RegisterResponse(session_id)

    Note over S,W: 3. Bidirectional Stream con Optimizaciones
    W->>S: WorkerStream (bidirectional)

    loop Heartbeat + Commands
        W->>S: WorkerHeartbeat (cached metrics)
        S-->>W: ACK / KeepAlive
        S->>W: RunJobCommand
        W->>W: Write-Execute Pattern
        W->>S: LogBatch (batched logs)
        W->>S: JobResultMessage (with secrets audit)
    end

    Note over S,W: 4. Shutdown
    W->>S: Unregister(reason)
    S->>P: destroy_worker(handle)
```

## Bounded Contexts

### 1. Job Execution Context

Responsable del ciclo de vida completo de un job.

```mermaid
classDiagram
    class Job {
        +JobId id
        +JobSpec spec
        +JobState state
        +ProviderId selected_provider
        +ExecutionContext execution_context
        +u32 attempts
        +u32 max_attempts
        +queue() Result
        +submit_to_provider() Result
        +mark_running() Result
        +complete() Result
        +fail() Result
        +cancel() Result
        +can_retry() bool
    }

    class JobSpec {
        +CommandType command
        +Option~String~ image
        +HashMap env
        +JobResources resources
        +u64 timeout_ms
        +Vec~Constraint~ constraints
        +Vec~ArtifactSource~ inputs
        +Vec~ArtifactDest~ outputs
    }

    class CommandType {
        <<enumeration>>
        Shell: cmd + args
        Script: interpreter + content
    }

    class JobResources {
        +f32 cpu_cores
        +u64 memory_mb
        +u64 storage_mb
        +bool gpu_required
        +String architecture
    }

    class JobPreferences {
        +Option~String~ preferred_provider
        +Option~String~ preferred_region
        +JobPriority priority
        +bool allow_retry
    }

    class ExecutionContext {
        +JobId job_id
        +ProviderId provider_id
        +String provider_execution_id
        +ExecutionStatus status
        +update_status()
    }

    Job --> JobSpec
    Job --> ExecutionContext
    JobSpec --> JobResources
    JobSpec --> JobPreferences
```

### 2. Provider Management Context

Gestiona los workers/providers que ejecutan jobs.

```mermaid
classDiagram
    class Provider {
        +ProviderId id
        +String name
        +ProviderType provider_type
        +ProviderStatus status
        +ProviderCapabilities capabilities
        +ProviderConfig config
        +u32 current_jobs
        +is_healthy() bool
        +is_available() bool
        +mark_healthy()
        +mark_unhealthy()
        +increment_job_count()
        +decrement_job_count()
    }

    class ProviderType {
        <<enumeration>>
        Lambda
        Kubernetes
        Docker
        AzureVm
        Ec2
        CloudRun
        BareMetal
        Custom
    }

    class ProviderCapabilities {
        +Option~u32~ max_cpu_cores
        +Option~u64~ max_memory_gb
        +bool supports_gpu
        +Vec~String~ supported_runtimes
        +Vec~String~ supported_architectures
        +Option~u32~ max_concurrent_jobs
    }

    class ProviderConfig {
        <<enumeration>>
        Lambda
        Kubernetes
        Docker
        AzureVm
        Ec2
        CloudRun
        BareMetal
    }

    Provider --> ProviderType
    Provider --> ProviderCapabilities
    Provider --> ProviderConfig
```

### 3. Shared Kernel

Tipos y conceptos compartidos entre contextos.

```mermaid
classDiagram
    class JobId {
        +Uuid value
        +new() JobId
    }

    class ProviderId {
        +Uuid value
        +new() ProviderId
    }

    class CorrelationId {
        +Uuid value
        +new() CorrelationId
    }

    class JobState {
        <<enumeration>>
        Pending
        Scheduled
        Running
        Succeeded
        Failed
        Cancelled
        Timeout
    }

    class WorkerState {
        <<enumeration>>
        Creating
        Connecting
        Ready
        Busy
        Draining
        Terminating
        Terminated
    }

    class ProviderStatus {
        <<enumeration>>
        Active
        Maintenance
        Disabled
        Overloaded
        Unhealthy
    }

    class DomainError {
        <<enumeration>>
        JobNotFound
        ProviderNotFound
        InvalidStateTransition
        ProviderUnhealthy
        MaxAttemptsExceeded
    }
```

## Estructura de Crates
No actualizado a la estructura actual. Tenerlo como referencia pero no es real.
```
hodei-job-platform/
â”œâ”€â”€ crates/
â”‚   â”œâ”€â”€ domain/           # hodei-jobs-domain - LÃ³gica de negocio pura
â”‚   â”‚   â”œâ”€â”€ shared_kernel.rs      # JobId, WorkerId, ProviderId, States, Errors
â”‚   â”‚   â”œâ”€â”€ job_execution.rs      # Job aggregate, JobSpec, JobQueue trait
â”‚   â”‚   â”œâ”€â”€ job_template.rs       # JobTemplate aggregate
â”‚   â”‚   â”œâ”€â”€ worker.rs             # Worker aggregate, WorkerSpec, WorkerHandle
â”‚   â”‚   â”œâ”€â”€ worker_provider.rs    # WorkerProvider trait, ProviderCapabilities
â”‚   â”‚   â”œâ”€â”€ worker_registry.rs    # WorkerRegistry trait
â”‚   â”‚   â”œâ”€â”€ job_scheduler.rs      # Scheduling strategies
â”‚   â”‚   â”œâ”€â”€ provider_config.rs    # ProviderConfig
â”‚   â”‚   â””â”€â”€ otp_token_store.rs    # OTP authentication
â”‚   â”‚
â”‚   â”œâ”€â”€ application/      # hodei-jobs-application - Use Cases
â”‚   â”‚   â”œâ”€â”€ job_execution_usecases.rs  # CreateJob, CancelJob
â”‚   â”‚   â”œâ”€â”€ job_controller.rs          # Control loop
â”‚   â”‚   â”œâ”€â”€ smart_scheduler.rs         # Scheduling service
â”‚   â”‚   â”œâ”€â”€ worker_provisioning.rs     # Worker provisioning trait
â”‚   â”‚   â”œâ”€â”€ worker_provisioning_impl.rs # Default implementation
â”‚   â”‚   â”œâ”€â”€ worker_lifecycle.rs        # Worker lifecycle management
â”‚   â”‚   â””â”€â”€ provider_registry.rs       # Provider management
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/   # hodei-jobs-infrastructure - Adapters
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”œâ”€â”€ docker.rs         # DockerProvider (bollard)
â”‚   â”‚   â”‚   â”œâ”€â”€ kubernetes.rs     # KubernetesProvider (kube-rs)
â”‚   â”‚   â”‚   â””â”€â”€ firecracker.rs    # FirecrackerProvider (KVM)
â”‚   â”‚   â”œâ”€â”€ persistence.rs        # Postgres repositories (sqlx)
â”‚   â”‚   â””â”€â”€ repositories.rs       # In-memory repositories
â”‚   â”‚
â”‚   â”œâ”€â”€ grpc/             # hodei-jobs-grpc - gRPC Services
â”‚   â”‚   â”œâ”€â”€ services/             # Service implementations
â”‚   â”‚   â”œâ”€â”€ proto/                # Protocol Buffers (LogBatch message)
â”‚   â”‚   â””â”€â”€ bin/
â”‚   â”‚       â”œâ”€â”€ server.rs         # Control plane server (mTLS ready)
â”‚   â”‚       â””â”€â”€ worker.rs         # Worker agent (HPC-ready)
â”‚   â”‚
â”‚   â”œâ”€â”€ interface/        # hodei-jobs-interface - REST API (Axum)
â”‚   â”‚
â”‚   â””â”€â”€ cli/              # hodei-jobs-cli - Command line interface
â”‚
â”œâ”€â”€ proto/                # Protocol Buffers definitions
â”œâ”€â”€ deploy/
â”‚   â””â”€â”€ kubernetes/       # K8s manifests (RBAC, NetworkPolicy)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ docker/           # Docker image build scripts
â”‚   â”œâ”€â”€ kubernetes/       # K8s image build scripts
â”‚   â”œâ”€â”€ firecracker/      # Firecracker rootfs build scripts
â”‚   â””â”€â”€ generate-certificates.sh  # PKI certificate generation
â””â”€â”€ docs/security/
    â”œâ”€â”€ PKI-DESIGN.md     # mTLS PKI architecture
    â””â”€â”€ CERTIFICATE-MANAGEMENT.md  # Operations guide
```

```mermaid
graph LR
    subgraph "Proto"
        PROTO[hodei-jobs<br/>Generated Types]
    end

    subgraph "Domain"
        DOM[hodei-jobs-domain<br/>Business Logic]
    end

    subgraph "Application"
        APP[hodei-jobs-application<br/>Use Cases]
    end

    subgraph "Infrastructure"
        INFRA[hodei-jobs-infrastructure<br/>Docker + K8s + Firecracker]
    end

    subgraph "Adapters"
        GRPC[hodei-jobs-grpc<br/>Server + Worker Agent]
        CLI[hodei-jobs-cli<br/>Command Line]
        REST[hodei-jobs-interface<br/>REST API]
    end

    PROTO --> GRPC
    PROTO --> CLI

    DOM --> APP
    APP --> GRPC
    APP --> REST

    INFRA --> APP
    INFRA --> GRPC
```

## Worker Agent - Componentes Internos (v8.0)

El worker agent es un sistema de alta performance con los siguientes componentes:

### Core Components

```mermaid
classDiagram
    class WorkerClient {
        +connection: GrpcConnection
        +stream: BidirectionalStream
        +register_worker() Result
        +start_worker_stream() Result
    }

    class LogBatcher {
        +tx: mpsc::Sender~WorkerMessage~
        +buffer: Vec~LogEntry~
        +capacity: usize
        +flush_interval: Duration
        +last_flush: Instant
        +flush() Task
        +add_entry() Result
    }

    class JobExecutor {
        +execute_shell() Result
        +execute_script_robust() Result
        +inject_secrets() Result
        +cleanup_temp_files() Task
    }

    class MetricsCollector {
        +cache: CachedResourceUsage
        +cache_ttl: Duration
        +get_usage() Result
        +spawn_blocking_task() Task
    }

    class CertificateManager {
        +paths: CertificatePaths
        +expiration: CertificateExpiration
        +load_certificates() Task
        +check_expiration() Task
    }

    WorkerClient --> LogBatcher
    WorkerClient --> JobExecutor
    WorkerClient --> MetricsCollector
    CertificateManager --> WorkerClient
```

### Data Structures

```rust
// LogBatcher - Batched log transmission
struct LogBatcher {
    tx: mpsc::Sender<WorkerMessage>,
    buffer: Vec<LogEntry>,
    capacity: usize,
    flush_interval: Duration,
    last_flush: Instant,
}

// CachedResourceUsage - TTL cache for metrics
struct CachedResourceUsage {
    usage: ResourceUsage,
    timestamp: Instant,
}
const METRICS_CACHE_TTL_SECS: u64 = 35;

// CertificatePaths - mTLS configuration
struct CertificatePaths {
    pub client_cert_path: PathBuf,
    pub client_key_path: PathBuf,
    pub ca_cert_path: PathBuf,
}

// LogBatch message - Reduced network overhead
message LogBatch {
    string job_id = 1;
    repeated LogEntry entries = 2;
}
```

### Performance Characteristics

| Componente | OptimizaciÃ³n | Beneficio |
|-----------|--------------|-----------|
| **LogBatcher** | Batch de 100 entries, flush cada 100ms | 90-99% reducciÃ³n gRPC calls |
| **Backpressure** | try_send() con drop en full | Prevenir blocking del async runtime |
| **Zero-Copy I/O** | FramedRead + BytesCodec | ReducciÃ³n allocaciones memoria |
| **Metrics Cache** | TTL 35s + spawn_blocking | Non-blocking metrics collection |
| **Write-Execute** | Temp files + async cleanup | Robustez en ejecuciÃ³n scripts |
| **Secret Injection** | stdin + JSON serialization | Seguridad sin exposiciÃ³n logs |

## Worker Providers

El sistema soporta mÃºltiples providers para ejecutar workers:

| Provider | Aislamiento | Startup | GPU | Requisitos |
|----------|-------------|---------|-----|------------|
| **Docker** | Container | ~1s | SÃ­ | Docker daemon |
| **Kubernetes** | Container (Pod) | ~5-15s | SÃ­ | K8s cluster |
| **Firecracker** | Hardware (KVM) | ~125ms | No | Linux + KVM |

### WorkerProvider Trait (ISP Refactoring - DEBT-001)

**Estado**: ðŸŸ¡ Fase 1 Completada - ISP traits segregados, trait combinado deprecated

```rust
// ISP Traits - Segregados (recomendado para nuevo cÃ³digo)
#[async_trait]
pub trait WorkerLifecycle: Send + Sync {
    async fn create_worker(&self, spec: &WorkerSpec) -> Result<WorkerHandle, ProviderError>;
    async fn get_worker_status(&self, handle: &WorkerHandle) -> Result<WorkerState, ProviderError>;
    async fn destroy_worker(&self, handle: &WorkerHandle) -> Result<(), ProviderError>;
}

#[async_trait]
pub trait WorkerHealth: Send + Sync {
    async fn health_check(&self) -> Result<HealthStatus, ProviderError>;
}

#[async_trait]
pub trait WorkerLogs: Send + Sync {
    async fn get_worker_logs(&self, handle: &WorkerHandle, tail: Option<u32>) 
        -> Result<Vec<LogEntry>, ProviderError>;
}

pub trait WorkerCost: Send + Sync {
    fn estimate_cost(&self, spec: &WorkerSpec, duration: Duration) -> Option<CostEstimate>;
    fn estimated_startup_time(&self) -> Duration;
}

// ... mÃ¡s ISP traits: WorkerEligibility, WorkerMetrics, WorkerEventSource, WorkerProviderIdentity

// Trait combinado (DEPRECATED - solo para backward compatibility)
#[deprecated(
    since = "0.83.0",
    note = "Use specific ISP traits (WorkerLifecycle, WorkerHealth, etc.) instead"
)]
#[async_trait]
pub trait WorkerProvider:
    WorkerProviderIdentity
    + WorkerLifecycle
    + WorkerLogs
    + WorkerCost
    + WorkerHealth
    + WorkerEligibility
    + WorkerMetrics
    + WorkerEventSource
    + Send
    + Sync
{
}
```

**Uso Recomendado (ISP-compliant)**:
```rust
// Cliente que solo necesita crear/destruir workers
struct SagaWorkerProvisioner {
    provider: Arc<dyn WorkerLifecycle + WorkerProviderIdentity>,
}

// Cliente que solo necesita health checks
struct MonitoringService {
    providers: Vec<Arc<dyn WorkerHealth>>,
}
```

**MigraciÃ³n**: Ver `docs/analysis/TECHNICAL_DEBT_SOLID_DDD.md#debt-001` para guÃ­a completa

### Variables de Entorno por Provider

**Docker:**
```bash
HODEI_DOCKER_ENABLED=1
HODEI_WORKER_IMAGE=hodei-worker:latest
```

**Kubernetes:**
```bash
HODEI_K8S_ENABLED=1
HODEI_K8S_NAMESPACE=hodei-workers
HODEI_K8S_KUBECONFIG=/path/to/kubeconfig  # opcional
```

**Firecracker:**
```bash
HODEI_FC_ENABLED=1
HODEI_FC_KERNEL_PATH=/var/lib/hodei/vmlinux
HODEI_FC_ROOTFS_PATH=/var/lib/hodei/rootfs.ext4
HODEI_FC_USE_JAILER=true
```

## Servicios gRPC

| Servicio | DescripciÃ³n | RPCs |
|----------|-------------|------|
| **WorkerAgentService** | ComunicaciÃ³n Serverâ†”Worker | `Register`, `WorkerStream`, `UpdateWorkerStatus`, `UnregisterWorker` |
| **JobExecutionService** | Ciclo de vida de ejecuciÃ³n | `QueueJob`, `AssignJob`, `StartJob`, `UpdateProgress`, `CompleteJob`, `FailJob`, `CancelJob`, `ExecutionEventStream` |
| **SchedulerService** | Scheduling inteligente | `ScheduleJob`, `GetSchedulingDecision`, `ConfigureScheduler`, `GetQueueStatus`, `GetAvailableWorkers`, `SchedulingDecisionStream` |
| **ProviderManagementService** | GestiÃ³n de providers | `RegisterProvider`, `ListProviders`, `GetProviderHealth` |
| **MetricsService** | MÃ©tricas | `StreamMetrics`, `GetAggregatedMetrics`, `GetTimeSeriesMetrics` |
| **LogStreamService** | Logs de job | `SubscribeLogs`, `GetLogs` |

> Nota: el `MetricsService` requiere un backend explÃ­cito. Por defecto el backend estÃ¡ deshabilitado.

## Persistencia (Postgres)

El sistema persiste su estado en Postgres mediante repositorios SQLx (infraestructura):

- `JobRepository` (jobs)
- `JobQueue` (cola de jobs)
- `WorkerRegistry` (workers)
- `ProviderConfigRepository` (providers)

Tanto el servidor gRPC como el adaptador REST ejecutan migraciones al arrancar.

### Variables de entorno (DB)

- `HODEI_DATABASE_URL` (o `DATABASE_URL`) **obligatoria**
- `HODEI_DB_MAX_CONNECTIONS` (default `10`)
- `HODEI_DB_CONNECTION_TIMEOUT_SECS` (default `30`)

## Puertos y entrypoints

- gRPC server: `crates/grpc/src/bin/server.rs` (default `GRPC_PORT=50051`)
- Worker Agent: `crates/grpc/src/bin/worker.rs` (conecta a `HODEI_SERVER`, default `http://localhost:50051`)
- REST API: `crates/interface` (Axum). Requiere Postgres (mismas variables DB).

### WorkerAgentService - Flujo Principal

```protobuf
service WorkerAgentService {
    // Registro con OTP token (PRD v6.0)
    rpc Register(RegisterWorkerRequest) returns (RegisterWorkerResponse);

    // Stream bidireccional para comandos y respuestas
    rpc WorkerStream(stream WorkerMessage) returns (stream ServerMessage);

    // Legacy RPCs
    rpc UpdateWorkerStatus(UpdateWorkerStatusRequest) returns (UpdateWorkerStatusResponse);
    rpc UnregisterWorker(UnregisterWorkerRequest) returns (UnregisterWorkerResponse);
}
```

### Mensajes del Stream

**Worker â†’ Server:**
- `WorkerHeartbeat` - Estado y recursos
- `LogEntry` - Logs de ejecuciÃ³n en tiempo real
- `JobResultMessage` - Resultado de job completado
- `WorkerStatsMessage` - EstadÃ­sticas del worker

**Server â†’ Worker:**
- `RunJobCommand` - Ejecutar un job
- `CancelJobCommand` - Cancelar job en ejecuciÃ³n
- `AckMessage` - ConfirmaciÃ³n de recepciÃ³n
- `KeepAliveMessage` - Mantener conexiÃ³n activa

## ComunicaciÃ³n entre Componentes

```mermaid
sequenceDiagram
    participant C as Client
    participant G as gRPC Gateway
    participant S as Service Layer
    participant A as Application Layer
    participant D as Domain Layer
    participant I as Infrastructure

    C->>G: gRPC Request
    G->>S: Parse & Validate
    S->>A: Execute Use Case
    A->>D: Domain Operations
    D->>D: Business Rules
    D-->>A: Domain Result
    A->>I: Persist Changes
    I-->>A: Confirmation
    A-->>S: Use Case Result
    S-->>G: Build Response
    G-->>C: gRPC Response
```
