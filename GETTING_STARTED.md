# Gu√≠a de Usuario - Hodei Jobs Platform

**Versi√≥n**: 8.0  
**√öltima Actualizaci√≥n**: 2025-12-16

Gu√≠a pr√°ctica para usuarios que quieren ejecutar jobs distribuidos usando la interfaz web de Hodei Jobs Platform.

## üìã √çndice

1. [Inicio R√°pido](#-inicio-r√°pido)
2. [Levantar la Aplicaci√≥n](#-levantar-la-aplicaci√≥n)
3. [Interfaz Web](#-interfaz-web)
   - [Dashboard](#dashboard)
   - [Crear un Job](#crear-un-job)
   - [Ver Detalles de un Job](#ver-detalles-de-un-job)
   - [Logs en Tiempo Real](#logs-en-tiempo-real)
   - [Historial de Jobs](#historial-de-jobs)
   - [Gesti√≥n de Providers](#gesti√≥n-de-providers)
   - [M√©tricas del Sistema](#m√©tricas-del-sistema)
4. [Ejemplos Pr√°cticos](#-ejemplos-pr√°cticos)
5. [Arquitectura del Sistema](#-arquitectura-del-sistema)
6. [Troubleshooting](#-troubleshooting)
7. [Referencia para Desarrolladores](#-referencia-para-desarrolladores)

---

## üöÄ Inicio R√°pido

En menos de 5 minutos puedes tener la plataforma funcionando y ejecutar tu primer job.

### Requisitos

- **Docker** y **Docker Compose** instalados
- Puerto `80` disponible (web)
- Puerto `50051` disponible (API gRPC)
- Puerto `5432` disponible (PostgreSQL)

### Pasos R√°pidos

```bash
# 1. Clonar el repositorio
git clone <repo-url>
cd hodei-jobs

# 2. Levantar toda la plataforma
docker compose -f docker-compose.prod.yml up -d

# 3. Abrir la interfaz web
open http://localhost  # macOS
xdg-open http://localhost  # Linux
```

¬°Listo! Ya puedes crear y ejecutar jobs desde la interfaz web.

## üê≥ Levantar la Aplicaci√≥n

### Opci√≥n 1: Producci√≥n (Recomendado)

Levanta toda la plataforma con un solo comando:

```bash
# Crear archivo de configuraci√≥n
cat > .env << EOF
POSTGRES_PASSWORD=tu-password-seguro
GRAFANA_PASSWORD=admin
EOF

# Levantar servicios principales
docker compose -f docker-compose.prod.yml up -d --build

# Ver logs
docker compose -f docker-compose.prod.yml logs -f

# Con monitoreo (Prometheus + Grafana)
docker compose -f docker-compose.prod.yml --profile monitoring up -d
```

**Servicios disponibles:**

| Servicio | URL | Descripci√≥n |
|----------|-----|-------------|
| **Web Dashboard** | http://localhost | Interfaz principal |
| **API gRPC** | localhost:50051 | API para clientes |
| **PostgreSQL** | localhost:5432 | Base de datos |
| **Prometheus** | http://localhost:9090 | M√©tricas (opcional) |
| **Grafana** | http://localhost:3000 | Dashboards (opcional) |

### Opci√≥n 2: Desarrollo Local

Para desarrollo, puedes levantar solo PostgreSQL y ejecutar el servidor localmente:

```bash
# Terminal 1: Base de datos
docker compose -f docker-compose.dev.yml up -d

# Terminal 2: Servidor backend
export HODEI_DATABASE_URL="postgres://postgres:postgres@localhost:5432/hodei"
export HODEI_DEV_MODE=1
export HODEI_DOCKER_ENABLED=1
cargo run --bin server -p hodei-jobs-grpc

# Terminal 3: Frontend web
cd web
npm install
npm run dev
```

### Verificar que todo funciona

```bash
# Ver estado de los contenedores
docker compose -f docker-compose.prod.yml ps

# Verificar API gRPC
grpcurl -plaintext localhost:50051 list

# Abrir la web
open http://localhost
```

---

## üñ•Ô∏è Interfaz Web

La interfaz web est√° dise√±ada para ser intuitiva y m√≥vil-first. Aqu√≠ te explicamos cada secci√≥n.

### Dashboard

**URL:** `/` (p√°gina principal)

El dashboard muestra un resumen del estado del sistema:

- **Total Jobs**: N√∫mero total de jobs ejecutados
- **Running**: Jobs en ejecuci√≥n actualmente
- **Failed**: Jobs que fallaron
- **Success**: Jobs completados exitosamente
- **System Health**: Carga de CPU y estado de los nodos
- **Recent Executions**: √öltimos 5 jobs ejecutados

**Acciones r√°pidas:**
- Clic en el bot√≥n **+** (azul, esquina inferior derecha) para crear un nuevo job
- Clic en "See All" para ver el historial completo
- Clic en cualquier job reciente para ver sus detalles

---

### Crear un Job

**URL:** `/jobs/new`

Formulario completo para programar un nuevo job:

#### 1. Basic Info
- **Job Name**: Nombre descriptivo del job (ej: "Data Processing Pipeline")

#### 2. Core Execution
- **Command Type**: Tipo de comando a ejecutar
  - `Shell Command`: Comandos bash/shell
  - `Docker Exec`: Ejecutar dentro de un contenedor
  - `Python Script`: Script Python
  - `Node.js Script`: Script Node.js
- **Command / Script Content**: El comando o script a ejecutar

#### 3. Environment & Image
- **Container Image**: Imagen Docker a usar (ej: `ubuntu:latest`, `python:3.9`)
- **Environment Variables**: Variables de entorno (clave=valor)

#### 4. Resources
- **CPU Cores**: N√∫mero de cores (1-16)
- **Memory (MB)**: Memoria RAM en MB
- **Storage (MB)**: Almacenamiento temporal
- **Timeout (ms)**: Tiempo m√°ximo de ejecuci√≥n
- **GPU Required**: Activar si necesitas GPU
- **Architecture**: `x86_64` o `arm64`

#### 5. Preferences
- **Provider**: Seleccionar provider espec√≠fico o "Any"
- **Region**: Regi√≥n preferida o "Auto"
- **Job Priority**: `Low`, `Normal`, o `High`
- **Allow Retry**: Reintentar autom√°ticamente si falla

**Ejemplo r√°pido:**
```
Job Name: Hello World Test
Command Type: Shell Command
Script: echo "Hello from Hodei!" && date
Container Image: alpine:latest
CPU Cores: 1
Memory: 512
```

Clic en **"Schedule Job"** para encolar el job.

---

### Ver Detalles de un Job

**URL:** `/jobs/:jobId`

Muestra informaci√≥n detallada de un job espec√≠fico:

#### Pesta√±as disponibles:

**Overview:**
- **Timeline**: Progreso del job (Queued ‚Üí Image Pulled ‚Üí Running ‚Üí Cleanup)
- **Live Resources**: Uso de CPU y memoria en tiempo real
- **Latest Logs**: Vista previa de los √∫ltimos logs

**Config:**
- Comando ejecutado
- Imagen utilizada
- L√≠mites de CPU y memoria

**Logs:**
- Enlace al visor de logs completo

**Resources:**
- Gr√°ficos detallados de uso de recursos

#### Acciones:
- **SSH Access**: Acceso directo al worker (si est√° disponible)
- **Cancel Job**: Cancelar el job en ejecuci√≥n

---

### Logs en Tiempo Real

**URL:** `/jobs/:jobId/logs`

Visor de logs estilo terminal con streaming en tiempo real:

**Caracter√≠sticas:**
- **B√∫squeda**: Filtrar logs por texto (grep)
- **Filtros por nivel**: All, INFO, WARN, ERROR
- **Pause/Resume**: Pausar el streaming para analizar
- **Auto-scroll**: Seguir autom√°ticamente los nuevos logs

**Colores de logs:**
- üîµ **INFO**: Informaci√≥n general (azul)
- üü° **WARN**: Advertencias (amarillo)
- üî¥ **ERROR**: Errores (rojo)

**Controles:**
- **Pause/Resume**: Pausar o continuar el streaming
- **Clear**: Limpiar la pantalla
- **Scroll to bottom**: Ir al final de los logs

---

### Historial de Jobs

**URL:** `/jobs`

Lista completa de todos los jobs con:
- ID del job
- Nombre
- Estado (Running, Success, Failed)
- Tiempo de ejecuci√≥n
- Fecha de creaci√≥n

**Filtros disponibles:**
- Por estado
- Por fecha
- Por nombre

---

### Gesti√≥n de Providers

**URL:** `/providers`

Lista de providers de infraestructura disponibles:

| Provider | Descripci√≥n |
|----------|-------------|
| **Docker** | Ejecuta jobs en contenedores Docker locales |
| **Kubernetes** | Ejecuta jobs como Pods en un cluster K8s |
| **Firecracker** | Ejecuta jobs en microVMs (m√°ximo aislamiento) |

**Acciones:**
- Ver detalles de cada provider
- Habilitar/deshabilitar providers
- Configurar par√°metros espec√≠ficos

#### Crear nuevo Provider

**URL:** `/providers/new`

Formulario para agregar un nuevo provider con su configuraci√≥n espec√≠fica.

---

### M√©tricas del Sistema

**URL:** `/metrics`

Dashboard de m√©tricas del sistema:
- Jobs por estado
- Tiempo promedio de ejecuci√≥n
- Uso de recursos por provider
- Tendencias hist√≥ricas

---

## üìù Ejemplos Pr√°cticos

### Ejemplo 1: Job Simple (Echo)

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `Hello World`
   - **Command Type**: `Shell Command`
   - **Script**: `echo "Hello from Hodei!" && date`
   - **Container Image**: `alpine:latest`
3. Clic en **Schedule Job**
4. Ver el progreso en `/jobs/:jobId`

### Ejemplo 2: Script Python

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `Python Data Processing`
   - **Command Type**: `Python Script`
   - **Script**:
     ```python
     import sys
     print("Processing data...")
     for i in range(5):
         print(f"Step {i+1}/5 completed")
     print("Done!")
     ```
   - **Container Image**: `python:3.11-slim`
   - **Memory**: `1024`
3. Clic en **Schedule Job**

### Ejemplo 3: Job con Variables de Entorno

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `API Data Fetch`
   - **Command Type**: `Shell Command`
   - **Script**: `curl -H "Authorization: Bearer $API_TOKEN" $API_URL`
   - **Container Image**: `curlimages/curl:latest`
   - **Environment Variables**:
     - `API_TOKEN` = `tu-token-secreto`
     - `API_URL` = `https://api.example.com/data`
3. Clic en **Schedule Job**

### Ejemplo 4: Job de Larga Duraci√≥n

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `Long Running Task`
   - **Command Type**: `Shell Command`
   - **Script**:
     ```bash
     for i in $(seq 1 60); do
       echo "[$(date)] Processing batch $i/60..."
       sleep 1
     done
     echo "All batches completed!"
     ```
   - **Container Image**: `alpine:latest`
   - **Timeout**: `120000` (2 minutos)
3. Clic en **Schedule Job**
4. Ir a `/jobs/:jobId/logs` para ver el progreso en tiempo real

---

## üèóÔ∏è Arquitectura del Sistema

### Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    HODEI JOBS PLATFORM                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Web UI    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ         gRPC Server (API)           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  (React)    ‚îÇ     ‚îÇ                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚Ä¢ JobExecutionService              ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚Ä¢ WorkerAgentService               ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚Ä¢ SchedulerService                 ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚Ä¢ LogStreamService                 ‚îÇ   ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                     ‚îÇ                          ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                      ‚îÇ         Worker Providers            ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚îÇ Docker ‚îÇ ‚îÇ  K8s   ‚îÇ ‚îÇFirecracker‚îÇ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ   ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                             ‚îÇ          ‚îÇ           ‚îÇ          ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                      ‚îÇContainer‚îÇ ‚îÇ   Pod   ‚îÇ ‚îÇ  microVM  ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ Worker  ‚îÇ ‚îÇ Worker  ‚îÇ ‚îÇ  Worker   ‚îÇ   ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de un Job

1. **Usuario crea job** desde la web
2. **Job se encola** en PostgreSQL con estado `PENDING`
3. **Scheduler detecta** el job pendiente
4. **Provider aprovisiona** un worker (container/pod/microVM)
5. **Worker se registra** autom√°ticamente con OTP
6. **Job se despacha** al worker
7. **Worker ejecuta** el comando y env√≠a logs en tiempo real
8. **Job completa** y el resultado se guarda

### Estados del Job

| Estado | Descripci√≥n |
|--------|-------------|
| `PENDING` | Esperando worker disponible |
| `ASSIGNED` | Asignado a un worker |
| `RUNNING` | En ejecuci√≥n |
| `SUCCEEDED` | Completado exitosamente |
| `FAILED` | Termin√≥ con error |
| `CANCELLED` | Cancelado por el usuario |
| `TIMEOUT` | Excedi√≥ el tiempo l√≠mite |

---

## üîß Troubleshooting

### La web no carga

```bash
# Verificar que los contenedores est√°n corriendo
docker compose -f docker-compose.prod.yml ps

# Ver logs del frontend
docker compose -f docker-compose.prod.yml logs web

# Reiniciar servicios
docker compose -f docker-compose.prod.yml restart
```

### Los jobs quedan en PENDING

```bash
# Verificar que hay providers habilitados
docker compose -f docker-compose.prod.yml logs api | grep -i provider

# Verificar Docker socket
docker ps

# Verificar logs del servidor
docker compose -f docker-compose.prod.yml logs api
```

### Error de conexi√≥n a PostgreSQL

```bash
# Verificar que PostgreSQL est√° corriendo
docker compose -f docker-compose.prod.yml logs postgres

# Verificar conectividad
docker exec hodei-jobs-postgres pg_isready -U postgres
```

### Los logs no aparecen en tiempo real

- Verificar que el job est√° en estado `RUNNING`
- Refrescar la p√°gina de logs
- Verificar la conexi√≥n WebSocket en las herramientas de desarrollo del navegador

### Limpiar y reiniciar todo

```bash
# Parar y eliminar todo
docker compose -f docker-compose.prod.yml down -v

# Reiniciar desde cero
docker compose -f docker-compose.prod.yml up -d
```

---

## üë®‚Äçüíª Referencia para Desarrolladores

Para informaci√≥n t√©cnica detallada sobre:
- Compilaci√≥n desde c√≥digo fuente
- Tests unitarios y de integraci√≥n
- API gRPC
- Desarrollo de nuevos providers

Consulta el archivo [DEVELOPMENT.md](./DEVELOPMENT.md) (pr√≥ximamente).

### Comandos √∫tiles para desarrollo

```bash
# Compilar el proyecto
cargo build --workspace

# Ejecutar tests
cargo test --workspace

# Verificar c√≥digo
cargo clippy --workspace

# Formatear c√≥digo
cargo fmt --all
```

### Variables de Entorno

| Variable | Descripci√≥n | Default |
|----------|-------------|---------|
| `HODEI_DATABASE_URL` | URL de PostgreSQL | - |
| `HODEI_DEV_MODE` | Modo desarrollo (acepta tokens dev-*) | `0` |
| `HODEI_DOCKER_ENABLED` | Habilitar Docker provider | `0` |
| `HODEI_K8S_ENABLED` | Habilitar Kubernetes provider | `0` |
| `HODEI_FC_ENABLED` | Habilitar Firecracker provider | `0` |
| `GRPC_PORT` | Puerto del servidor gRPC | `50051` |
| `RUST_LOG` | Nivel de logs | `info` |

---

## üìö Recursos Adicionales

- **README.md**: Descripci√≥n general del proyecto
- **README_ES.md**: README en espa√±ol
- **docker-compose.prod.yml**: Configuraci√≥n de producci√≥n
- **docker-compose.dev.yml**: Configuraci√≥n de desarrollo

---

*¬øTienes preguntas? Abre un issue en el repositorio.*
