# Gu√≠a de Usuario - Hodei Jobs Platform

**Versi√≥n**: 8.0
**√öltima Actualizaci√≥n**: 2025-12-17

---

## üöÄ NUEVAS MEJORAS - Worker Agent v0.1.5

**Fecha**: 2025-12-17  
**Versi√≥n**: 0.1.5

### Mejoras Implementadas (Basadas en Jenkins/K8s/GitHub Actions)

#### 1. ‚úÖ Ejecuci√≥n de Comandos con Shell
El worker ahora **siempre usa `/bin/bash -c`** para ejecutar comandos (como Jenkins, Kubernetes Jobs, GitHub Actions):

**Beneficios**:
- ‚úÖ Soporte para pipes y redirecciones: `echo "test" | grep test`
- ‚úÖ Variables de entorno: `echo $HOME`
- ‚úÖ Comandos compuestos: `cd /tmp && ls -la`
- ‚úÖ Wildcards: `ls *.txt`
- ‚úÖ Builtins del shell: `source`, `export`, `cd`

**Ejemplo**:
```bash
cargo run --bin hodei-jobs-cli -- job queue \
  --name "Pipeline Test" \
  --command "echo 'Step 1' && sleep 1 && echo 'Step 2' | grep 'Step'"
```

#### 2. ‚úÖ Streaming de Logs Mejorado
Logs ahora se env√≠an **l√≠nea por l√≠nea** en tiempo real (como Jenkins/K8s):
- Marcadores `$` para comandos ejecutados
- Separaci√≥n clara de stdout/stderr
- Timestamps en cada entrada
- Buffers optimizados para alto throughput

#### 3. ‚úÖ Soporte para Timeouts
Jobs pueden especificar timeout (como Kubernetes Jobs):
```rust
// Timeout de 5 minutos por defecto
// Configurable via RunJobMessage.timeout_ms
```

#### 4. ‚úÖ Ejecuci√≥n de Scripts Mejorada
Scripts muestran header y contenido como logs (como Jenkins):
```bash
$ /bin/bash -c << 'EOF'
# Script content visible in logs
echo "Script started"
# ...
EOF
```

### C√≥mo Usar

**Encolar Job Simple**:
```bash
cargo run --bin hodei-jobs-cli -- job queue \
  --name "Echo Test" \
  --command "echo 'Hello from worker!'"
```

**Encolar Job con Pipeline**:
```bash
cargo run --bin hodei-jobs-cli -- job queue \
  --name "Pipeline Test" \
  --command "cat /etc/os-release | grep PRETTY_NAME"
```

**Encolar Job Multi-Step**:
```bash
cargo run --bin hodei-jobs-cli -- job queue \
  --name "Multi-step" \
  --command "cd /tmp && pwd && ls -la && echo 'Done!'"
```

**Monitorear Logs**:
```bash
just watch-logs
# o
./scripts/watch_logs.sh
```

### Problema Conocido

‚ö†Ô∏è **Docker Provider - Variables de Entorno**: Los workers auto-provisionados necesitan correcci√≥n en `DockerProvider::create_container()` para recibir variables de entorno. **Trabajo futuro**.

---

## üîß ACTUALIZACI√ìN IMPORTANTE - Worker Auto-Provisioning Fix

**Estado**: ‚úÖ CORREGIDO  
**Fecha**: 2025-12-17  
**Versi√≥n**: 0.1.5

### ¬øQu√© se corrigi√≥?

El sistema ahora implementa correctamente el aprovisionamiento autom√°tico de workers seg√∫n PRD v7.0:

- ‚úÖ **Workers Fantasma Eliminados**: Workers obsoletos (>60s sin heartbeat) ahora se filtran
- ‚úÖ **Auto-Aprovisionamiento Funciona**: Cuando no hay workers disponibles, el sistema aprovisiona nuevos autom√°ticamente
- ‚úÖ **Arquitectura Event-Driven**: JobController responde a eventos y activa el aprovisionamiento
- ‚úÖ **Flujo E2E Completo**: Job ‚Üí Encolar ‚Üí Provisionar Worker ‚Üí Registrar ‚Üí Ejecutar ‚Üí Stream de Logs

### C√≥mo Usar (Desarrollo)

**Opci√≥n 1: Docker Compose Actualizado (con Docker-in-Docker)**

```bash
cd /home/rubentxu/Proyectos/rust/package/hodei-job-platform
docker compose -f docker-compose.dev.yml up -d
```

**Opci√≥n 2: Servidor Manual con Docker Socket**

```bash
docker run -d \
  --name hodei-jobs-api \
  -v /var/run/docker.sock:/var/run/docker.sock:ro \
  --network hodei-job-platform_hodei-jobs-internal \
  -p 50051:50051 \
  -e HODEI_DATABASE_URL=postgres://hodei:secure_password_here@postgres:5432/hodei \
  -e HODEI_DOCKER_ENABLED=1 \
  -e HODEI_PROVISIONING_ENABLED=1 \
  hodei-jobs-server:latest
```

### Probar Aprovisionamiento de Worker

```bash
# Encolar un job de prueba
cargo run --bin hodei-jobs-cli -- job queue \
  --name "Test Auto-Provisioning" \
  --command "echo 'Worker aprovisionado correctamente!'"

# Ver logs en tiempo real
just watch-logs

# Verificar workers aprovisionados en la base de datos
docker exec hodei-jobs-postgres psql -U hodei -d hodei -c \
  "SELECT id, state, created_at FROM workers ORDER BY created_at DESC LIMIT 5;"
```

**Flujo Esperado**:
1. Job encolado exitosamente ‚úÖ
2. Servidor detecta 0 workers disponibles ‚úÖ
3. Auto-aprovisiona nuevo contenedor Docker worker ‚úÖ
4. Worker se conecta y registra con el servidor ‚úÖ
5. Job asignado al worker ‚úÖ
6. Worker ejecuta job y env√≠a logs ‚úÖ

---

Gu√≠a pr√°ctica para usuarios que quieren ejecutar jobs distribuidos usando la interfaz web de Hodei Jobs Platform.

## üìã √çndice

1. [Inicio R√°pido](#-inicio-r√°pido)
2. [Levantar la Aplicaci√≥n](#-levantar-la-aplicaci√≥n)
3. [Interfaz Web](#-interfaz-web)
   - [Dashboard](#dashboard)
   - [Crear un Job](#crear-un-job)
   - [Ver Detalles de un Job](#ver-detalles-de-un-job)
   - [Logs en Tiempo Real](#logs-en-tiempo-real)
   - [Historial de Jobs](#historial-de-jobs)
   - [Gesti√≥n de Providers](#gesti√≥n-de-providers)
   - [M√©tricas del Sistema](#m√©tricas-del-sistema)
4. [Ejemplos Pr√°cticos](#-ejemplos-pr√°cticos)
5. [Arquitectura del Sistema](#-arquitectura-del-sistema)
6. [Troubleshooting](#-troubleshooting)
7. [Referencia para Desarrolladores](#-referencia-para-desarrolladores)

---

## üöÄ Inicio R√°pido

En menos de 5 minutos puedes tener la plataforma funcionando y ejecutar tu primer job.

### Requisitos

- **Docker** y **Docker Compose** instalados
- Puerto `80` disponible (web)
- Puerto `50051` disponible (API gRPC)
- Puerto `5432` disponible (PostgreSQL)

### Pasos R√°pidos

```bash
# 1. Clonar el repositorio
git clone <repo-url>
cd hodei-jobs

# 2. Configurar variables de entorno
cat > .env << EOF
POSTGRES_PASSWORD=secure_password_here
EOF

# 3. Levantar toda la plataforma
docker compose -f docker-compose.prod.yml up -d

# 4. Abrir la interfaz web
open http://localhost  # macOS
xdg-open http://localhost  # Linux
```

¬°Listo! Ya puedes crear y ejecutar jobs desde la interfaz web.

## üê≥ Levantar la Aplicaci√≥n

### Opci√≥n 1: Producci√≥n (Recomendado)

Levanta toda la plataforma con un solo comando:

```bash
# Crear archivo de configuraci√≥n
cat > .env << EOF
POSTGRES_PASSWORD=tu-password-seguro
GRAFANA_PASSWORD=admin
EOF



# Construir la imagen del Worker (CR√çTICO: Necesaria para Docker/K8s Providers)
docker build -f Dockerfile.worker -t hodei-jobs-worker:latest .

# Levantar servicios principales
docker compose -f docker-compose.prod.yml up -d --build

# Ver logs
docker compose -f docker-compose.prod.yml logs -f

# Con monitoreo (Prometheus + Grafana)
docker compose -f docker-compose.prod.yml --profile monitoring up -d
```

**Servicios disponibles:**

| Servicio          | URL                   | Descripci√≥n           |
| ----------------- | --------------------- | --------------------- |
| **Web Dashboard** | http://localhost      | Interfaz principal    |
| **API gRPC**      | localhost:50051       | API para clientes     |
| **PostgreSQL**    | localhost:5432        | Base de datos         |
| **Prometheus**    | http://localhost:9090 | M√©tricas (opcional)   |
| **Grafana**       | http://localhost:3000 | Dashboards (opcional) |

### Opci√≥n 2: Desarrollo Local (Optimizado)

Hemos simplificado el flujo de desarrollo para que sea ultra-r√°pido.

### 1. Setup Inicial (solo la primera vez)

```bash
./scripts/setup.sh
```

Esto instalar√°:

- Rust (cargo, rustc)
- Node.js & npm
- Docker & docker-compose
- Herramientas auxiliares (`just`, `bacon`, `buf`)
- Dependencias del proyecto

Si prefieres una instalaci√≥n m√≠nima (sin herramientas opcionales):

```bash
./scripts/setup.sh --minimal
```

### 2. Iniciar el Entorno de Desarrollo

El script `dev.sh` levanta todo el entorno (base de datos, backend, frontend) con hot-reload habilitado.

```bash
./scripts/dev.sh
```

El script `./scripts/dev.sh` levantar√° autom√°ticamente:

- PostgreSQL (en Docker)
- Backend (con Hot Reload via Bacon)
- Frontend (con HMR via Vite)

Tambi√©n puedes usar comandos individuales si lo prefieres:

```bash
./scripts/dev.sh db       # Solo base de datos
./scripts/dev.sh backend  # Solo backend
./scripts/dev.sh frontend # Solo frontend
```

### Verificar que todo funciona

```bash
# Ver estado de los contenedores
docker compose -f docker-compose.prod.yml ps

# Verificar API gRPC
grpcurl -plaintext localhost:50051 list

# Abrir la web
open http://localhost
```

---

## üñ•Ô∏è Interfaz Web

La interfaz web est√° dise√±ada para ser intuitiva y m√≥vil-first. Aqu√≠ te explicamos cada secci√≥n.

### Dashboard

**URL:** `/` (p√°gina principal)

El dashboard muestra un resumen del estado del sistema:

- **Total Jobs**: N√∫mero total de jobs ejecutados
- **Running**: Jobs en ejecuci√≥n actualmente
- **Failed**: Jobs que fallaron
- **Success**: Jobs completados exitosamente
- **System Health**: Carga de CPU y estado de los nodos
- **Recent Executions**: √öltimos 5 jobs ejecutados

**Acciones r√°pidas:**

- Clic en el bot√≥n **+** (azul, esquina inferior derecha) para crear un nuevo job
- Clic en "See All" para ver el historial completo
- Clic en cualquier job reciente para ver sus detalles

---

### Crear un Job

**URL:** `/jobs/new`

Formulario completo para programar un nuevo job:

#### 1. Basic Info

- **Job Name**: Nombre descriptivo del job (ej: "Data Processing Pipeline")

#### 2. Core Execution

- **Command Type**: Tipo de comando a ejecutar
  - `Shell Command`: Comandos bash/shell
  - `Docker Exec`: Ejecutar dentro de un contenedor
  - `Python Script`: Script Python
  - `Node.js Script`: Script Node.js
- **Command / Script Content**: El comando o script a ejecutar

#### 3. Environment & Image

- **Container Image**: Imagen Docker a usar (ej: `ubuntu:latest`, `python:3.9`)
- **Environment Variables**: Variables de entorno (clave=valor)

#### 4. Resources

- **CPU Cores**: N√∫mero de cores (1-16)
- **Memory (MB)**: Memoria RAM en MB
- **Storage (MB)**: Almacenamiento temporal
- **Timeout (ms)**: Tiempo m√°ximo de ejecuci√≥n
- **GPU Required**: Activar si necesitas GPU
- **Architecture**: `x86_64` o `arm64`

#### 5. Preferences

- **Provider**: Seleccionar provider espec√≠fico o "Any"
- **Region**: Regi√≥n preferida o "Auto"
- **Job Priority**: `Low`, `Normal`, o `High`
- **Allow Retry**: Reintentar autom√°ticamente si falla

**Ejemplo r√°pido:**

```
Job Name: Hello World Test
Command Type: Shell Command
Script: echo "Hello from Hodei!" && date
Container Image: alpine:latest
CPU Cores: 1
Memory: 512
```

Clic en **"Schedule Job"** para encolar el job.

---

### Ver Detalles de un Job

**URL:** `/jobs/:jobId`

Muestra informaci√≥n detallada de un job espec√≠fico:

#### Pesta√±as disponibles:

**Overview:**

- **Timeline**: Progreso del job (Queued ‚Üí Image Pulled ‚Üí Running ‚Üí Cleanup)
- **Live Resources**: Uso de CPU y memoria en tiempo real
- **Latest Logs**: Vista previa de los √∫ltimos logs

**Config:**

- Comando ejecutado
- Imagen utilizada
- L√≠mites de CPU y memoria

**Logs:**

- Enlace al visor de logs completo

**Resources:**

- Gr√°ficos detallados de uso de recursos

#### Acciones:

- **SSH Access**: Acceso directo al worker (si est√° disponible)
- **Cancel Job**: Cancelar el job en ejecuci√≥n

---

### Logs en Tiempo Real

**URL:** `/jobs/:jobId/logs`

Visor de logs estilo terminal con streaming en tiempo real:

**Caracter√≠sticas:**

- **B√∫squeda**: Filtrar logs por texto (grep)
- **Filtros por nivel**: All, INFO, WARN, ERROR
- **Pause/Resume**: Pausar el streaming para analizar
- **Auto-scroll**: Seguir autom√°ticamente los nuevos logs

**Colores de logs:**

- üîµ **INFO**: Informaci√≥n general (azul)
- üü° **WARN**: Advertencias (amarillo)
- üî¥ **ERROR**: Errores (rojo)

**Controles:**

- **Pause/Resume**: Pausar o continuar el streaming
- **Clear**: Limpiar la pantalla
- **Scroll to bottom**: Ir al final de los logs

---

### Historial de Jobs

**URL:** `/jobs`

Lista completa de todos los jobs con:

- ID del job
- Nombre
- Estado (Running, Success, Failed)
- Tiempo de ejecuci√≥n
- Fecha de creaci√≥n

**Filtros disponibles:**

- Por estado
- Por fecha
- Por nombre

---

### Gesti√≥n de Providers

**URL:** `/providers`

Lista de providers de infraestructura disponibles:

| Provider        | Descripci√≥n                                   |
| --------------- | --------------------------------------------- |
| **Docker**      | Ejecuta jobs en contenedores Docker locales   |
| **Kubernetes**  | Ejecuta jobs como Pods en un cluster K8s      |
| **Firecracker** | Ejecuta jobs en microVMs (m√°ximo aislamiento) |

**Acciones:**

- Ver detalles de cada provider
- Habilitar/deshabilitar providers
- Configurar par√°metros espec√≠ficos

#### Crear nuevo Provider

**URL:** `/providers/new`

Formulario para agregar un nuevo provider con su configuraci√≥n espec√≠fica.

---

### M√©tricas del Sistema

**URL:** `/metrics`

Dashboard de m√©tricas del sistema:

- Jobs por estado
- Tiempo promedio de ejecuci√≥n
- Uso de recursos por provider
- Tendencias hist√≥ricas

---

## üìù Ejemplos Pr√°cticos

### Ejemplo 1: Job Simple (Echo)

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `Hello World`
   - **Command Type**: `Shell Command`
   - **Script**: `echo "Hello from Hodei!" && date`
   - **Container Image**: `alpine:latest`
3. Clic en **Schedule Job**
4. Ver el progreso en `/jobs/:jobId`

### Ejemplo 2: Script Python

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `Python Data Processing`
   - **Command Type**: `Python Script`
   - **Script**:
     ```python
     import sys
     print("Processing data...")
     for i in range(5):
         print(f"Step {i+1}/5 completed")
     print("Done!")
     ```
   - **Container Image**: `python:3.11-slim`
   - **Memory**: `1024`
3. Clic en **Schedule Job**

### Ejemplo 3: Job con Variables de Entorno

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `API Data Fetch`
   - **Command Type**: `Shell Command`
   - **Script**: `curl -H "Authorization: Bearer $API_TOKEN" $API_URL`
   - **Container Image**: `curlimages/curl:latest`
   - **Environment Variables**:
     - `API_TOKEN` = `tu-token-secreto`
     - `API_URL` = `https://api.example.com/data`
3. Clic en **Schedule Job**

### Ejemplo 4: Job de Larga Duraci√≥n

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `Long Running Task`
   - **Command Type**: `Shell Command`
   - **Script**:
     ```bash
     for i in $(seq 1 60); do
       echo "[$(date)] Processing batch $i/60..."
       sleep 1
     done
     echo "All batches completed!"
     ```
   - **Container Image**: `alpine:latest`
   - **Timeout**: `120000` (2 minutos)
3. Clic en **Schedule Job**
4. Ir a `/jobs/:jobId/logs` para ver el progreso en tiempo real

---

## üîç Verificaci√≥n Avanzada (Eventos y Auditor√≠a)

Para asegurar que los jobs se est√°n ejecutando correctamente y generando los eventos de dominio esperados, puedes consultar directamente el sistema de auditor√≠a.

### Consultar Logs de Auditor√≠a (SQL)

Con√©ctate a la base de datos PostgreSQL corriendo en Docker.
_Nota: El usuario por defecto en desarrollo es `postgres`, en producci√≥n suele ser `hodei`._

```bash
# Opci√≥n A: Entorno Desarrollo
docker exec -it hodei-jobs-postgres psql -U postgres -d hodei

# Opci√≥n B: Entorno Producci√≥n (o Inicio R√°pido)
docker exec -it hodei-jobs-postgres psql -U hodei -d hodei

# Ejecutar query directa:
docker exec hodei-jobs-postgres psql -U hodei -d hodei -c "SELECT * FROM audit_logs LIMIT 5;"
```

### Consultas √ötiles

#### 1. Ver √∫ltimos eventos registrados

Verifica qu√© est√° pasando en el sistema en tiempo real.

```sql
SELECT occurred_at, event_type, actor, payload
FROM audit_logs
ORDER BY occurred_at DESC
LIMIT 10;
```

#### 2. Seguir el ciclo de vida de un Job espec√≠fico

Usando el `correlation_id` (que suele ser el Job ID para eventos de Job), puedes ver toda la historia de un job.

```sql
-- Reemplaza 'JOB_ID_AQUI' con el ID real de tu job
SELECT occurred_at, event_type, payload
FROM audit_logs
WHERE correlation_id = 'JOB_ID_AQUI'
ORDER BY occurred_at ASC;
```

> [!NOTE]
> Gracias a las mejoras recientes, **todos** los eventos del ciclo de vida (incluyendo √©xito/fallo) ahora incluyen el `correlation_id`, facilitando el seguimiento completo con esta √∫nica query.

### Verificaci√≥n del Ciclo de Vida (Orden de Eventos)

Para certificar que el flujo funciona correctamente, el orden cronol√≥gico de los eventos debe ser:

1.  **`JobCreated`**: El job entra al sistema (estado `Queued`).
2.  **`JobAssigned`**: El Scheduler asigna un worker.
3.  **`JobStatusChanged`** (Scheduled -> Running): El worker confirma el inicio de la ejecuci√≥n.
4.  **`JobStatusChanged`** (Running -> Succeeded/Failed): El worker reporta la finalizaci√≥n.

##### 5. Verificaci√≥n de Logs y Trazas (NUEVO)

Para capturar y persistir las trazas de ejecuci√≥n de los jobs en tiempo real durante el desarrollo, utiliza el comando:

```bash
just watch-logs
```

Este script se conectar√° al servidor gRPC, detectar√° jobs en ejecuci√≥n y guardar√° sus trazas en:

- **Directorio**: `build/logs/`
- **Formato**: `<job_id>.log`

Es una herramienta de desarrollo externa que no afecta al c√≥digo productivo del servidor.

#### Ejemplos de Verificaci√≥n

Puedes probar el sistema enviando diferentes tipos de jobs y observando c√≥mo aparecen sus trazas en `build/logs/*.log`.

**1. Job Simple**

```bash
cargo run --bin hodei-jobs-cli -- job queue --name "Hola Mundo" --command "echo 'Hola Hodei desde el Worker!'"
```

_Salida esperada:_

```
Starting: echo 'Hola Hodei desde el Worker!' []
Hola Hodei desde el Worker!
Completed: exit_code=0
```

**2. Job de Larga Duraci√≥n (para ver streaming)**

```bash
cargo run --bin hodei-jobs-cli -- job queue --name "Loop Test" --command "sh -c 'for i in 1 2 3 4 5; do echo \"Log Line \$i\"; sleep 1; done'"
```

_Si tienes `just watch-logs` corriendo, ver√°s aparecer las l√≠neas una a una en el fichero correspondiente._

**3. Verificaci√≥n de Entorno**

```bash
cargo run --bin hodei-jobs-cli -- job queue --name "Env Check" --command "env"
```

_√ötil para verificar qu√© variables de entorno ve el worker (e.g., `HODEI_WORKER_ID`)._

### 6. Limpieza (Worker Release)

Para verificar que el worker se libera correctamente tras finalizar el job, busca los eventos de latido (`WorkerHeartbeat`) o consulta el estado del worker. En entornos din√°micos (Docker), deber√≠as ver que el contenedor se detiene y elimina si la pol√≠tica de escalado as√≠ lo dicta.

**Verificar liberaci√≥n en logs del servidor:**

```bash
docker compose -f docker-compose.dev.yml logs api | grep "released"
```

### Verificaci√≥n de Logs de Ejecuci√≥n

Para confirmar que la salida del job (`stdout`/`stderr`) se transmite y registra correctamente:

1.  **Logs del Contenedor Worker** (si a√∫n existe):

    ```bash
    # Listar contenedores de workers (incluso detenidos)
    docker ps -a --filter "name=hodei-worker"

    # Ver logs espec√≠ficos
    docker logs <CONTAINER_ID>
    ```

2.  **Confirmar Recepci√≥n en el Servidor**:
    El servidor recibe los logs v√≠a gRPC y los registra (nivel DEBUG/INFO).
    ```bash
    docker logs hodei-jobs-api 2>&1 | grep "Log appended"
    ```

#### 3. Estad√≠sticas de Ejecuci√≥n

Cuenta cu√°ntos jobs han sido creados vs completados.

```sql
SELECT event_type, COUNT(*) as total
FROM audit_logs
GROUP BY event_type
ORDER BY total DESC;
```

### Verificaci√≥n de Integridad

Si un job parece "atascado", busca si falta alguno de los eventos intermedios. Por ejemplo, si ves `JobCreated` pero nunca `JobAssigned`, el problema est√° en el Scheduler o en la falta de recursos (Providers).

```sql
-- Buscar jobs hu√©rfanos (creados hace m√°s de 5 min sin asignar)
SELECT * FROM audit_logs
WHERE event_type = 'JobCreated'
AND occurred_at < NOW() - INTERVAL '5 minutes'
AND correlation_id NOT IN (
    SELECT correlation_id FROM audit_logs WHERE event_type = 'JobAssigned'
);
```

---

## üèóÔ∏è Arquitectura del Sistema

### Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    HODEI JOBS PLATFORM                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Web UI    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ         gRPC Server (API)           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  (React)    ‚îÇ     ‚îÇ                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚Ä¢ JobExecutionService              ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚Ä¢ WorkerAgentService               ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚Ä¢ SchedulerService                 ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚Ä¢ LogStreamService                 ‚îÇ   ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                     ‚îÇ                          ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                      ‚îÇ         Worker Providers            ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚îÇ Docker ‚îÇ ‚îÇ  K8s   ‚îÇ ‚îÇFirecracker‚îÇ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ   ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                             ‚îÇ          ‚îÇ           ‚îÇ          ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                      ‚îÇContainer‚îÇ ‚îÇ   Pod   ‚îÇ ‚îÇ  microVM  ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ Worker  ‚îÇ ‚îÇ  Worker  ‚îÇ ‚îÇ  Worker   ‚îÇ   ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de un Job

1. **Usuario crea job** desde la web
2. **Job se encola** en PostgreSQL con estado `PENDING`
3. **Scheduler detecta** el job pendiente
4. **Provider aprovisiona** un worker (container/pod/microVM)
5. **Worker se registra** autom√°ticamente con OTP
6. **Job se despacha** al worker
7. **Worker ejecuta** el comando y env√≠a logs en tiempo real
8. **Job completa** y el resultado se guarda

### Estados del Job

| Estado      | Descripci√≥n                 |
| ----------- | --------------------------- |
| `PENDING`   | Esperando worker disponible |
| `ASSIGNED`  | Asignado a un worker        |
| `RUNNING`   | En ejecuci√≥n                |
| `SUCCEEDED` | Completado exitosamente     |
| `FAILED`    | Termin√≥ con error           |
| `CANCELLED` | Cancelado por el usuario    |
| `TIMEOUT`   | Excedi√≥ el tiempo l√≠mite    |

---

## üîß Troubleshooting

### La web no carga

```bash
# Verificar que los contenedores est√°n corriendo
docker compose -f docker-compose.prod.yml ps

# Ver logs del frontend
docker compose -f docker-compose.prod.yml logs web

# Reiniciar servicios
docker compose -f docker-compose.prod.yml restart
```

### Los jobs quedan en PENDING

```bash
# Verificar que hay providers habilitados
docker compose -f docker-compose.prod.yml logs api | grep -i provider

# Verificar Docker socket
docker ps

# Verificar logs del servidor
docker compose -f docker-compose.prod.yml logs api
```

### Error de conexi√≥n a PostgreSQL

```bash
# Verificar que PostgreSQL est√° corriendo
docker compose -f docker-compose.prod.yml logs postgres

# Verificar conectividad
docker exec hodei-jobs-postgres pg_isready -U postgres
```

### Los logs no aparecen en tiempo real

- Verificar que el job est√° en estado `RUNNING`
- Refrescar la p√°gina de logs
- Verificar la conexi√≥n WebSocket en las herramientas de desarrollo del navegador

### Limpiar y reiniciar todo

```bash
# Parar y eliminar todo
docker compose -f docker-compose.prod.yml down -v

# Reiniciar desde cero
docker compose -f docker-compose.prod.yml up -d
```

---

## üë®‚Äçüíª Referencia para Desarrolladores

Para informaci√≥n t√©cnica detallada sobre:

- Compilaci√≥n desde c√≥digo fuente
- Tests unitarios y de integraci√≥n
- API gRPC
- Desarrollo de nuevos providers

Consulta el archivo [DEVELOPMENT.md](./DEVELOPMENT.md) para la gu√≠a completa.

### Comandos √∫tiles (Justfile)

Usamos `just` para automatizar tareas comunes. Ejecuta `just --list` para ver todos los comandos disponibles.

```bash
# Desarrollo
just dev            # Inicia todo el entorno
just dev-db         # Inicia solo la base de datos
just dev-backend    # Inicia backend con hot reload

# Testing
just test           # Ejecuta todos los tests
just test-backend   # Tests de backend
just test-e2e       # Tests end-to-end

# Calidad de C√≥digo
just check          # Lint y format check
just clean          # Limpiar artefactos
```

### Variables de Entorno

| Variable               | Descripci√≥n                            | Default |
| ---------------------- | -------------------------------------- | ------- |
| `HODEI_DATABASE_URL`   | URL de PostgreSQL                      | -       |
| `HODEI_DEV_MODE`       | Modo desarrollo (acepta tokens dev-\*) | `0`     |
| `HODEI_DOCKER_ENABLED` | Habilitar Docker provider              | `0`     |
| `HODEI_K8S_ENABLED`    | Habilitar Kubernetes provider          | `0`     |
| `HODEI_FC_ENABLED`     | Habilitar Firecracker provider         | `0`     |
| `GRPC_PORT`            | Puerto del servidor gRPC               | `50051` |
| `RUST_LOG`             | Nivel de logs                          | `info`  |

---

## üìö Recursos Adicionales

- **README.md**: Descripci√≥n general del proyecto
- **README_ES.md**: README en espa√±ol
- **docker-compose.prod.yml**: Configuraci√≥n de producci√≥n
- **docker-compose.dev.yml**: Configuraci√≥n de desarrollo

---

## üèóÔ∏è Ejemplo Avanzado: Job de Build Maven

Este ejemplo demuestra c√≥mo ejecutar un job complejo de build Maven usando Hodei Jobs Platform. El job incluye:

1. **Instalaci√≥n de dependencias**: Java y Maven
2. **Clonado de repositorio**: Descarga c√≥digo fuente desde Git
3. **Compilaci√≥n**: Ejecuta `mvn clean install`
4. **Logging en tiempo real**: Monitorea el progreso

### Opci√≥n 1: Ejecutar con CLI (Recomendado)

```bash
# Encolar job Maven simple
cargo run --bin hodei-jobs-cli -- job queue \
  --name "maven-build-simple" \
  --command "cd /tmp && git clone https://github.com/jenkins-docs/simple-java-maven-app.git && cd simple-java-maven-app && mvn clean install -B" \
  --timeout 300

# Ver logs en tiempo real
just watch-logs
```

### Opci√≥n 2: Ejecutar con Script Completo (asdf + Git)

Para un job m√°s complejo que instala Java/Maven con asdf:

```bash
# Ejecutar el script de verificaci√≥n
./scripts/verification/maven_build_job.sh
```

Este script:
- Instala asdf si no est√° disponible
- Configura Java 21 y Maven 3.9.9
- Clona el repositorio de ejemplo
- Ejecuta el build completo
- Muestra el resultado

### Opci√≥n 3: Ejecutar con gRPC Directo

```bash
# Usar el payload JSON predefinido
cat > /tmp/job_payload.json << 'EOF'
{
  "job_definition": {
    "name": "maven-build-complex",
    "command": "/bin/bash",
    "arguments": ["-c", "cd /tmp && git clone https://github.com/jenkins-docs/simple-java-maven-app.git && cd simple-java-maven-app && mvn clean install -B"],
    "requirements": {
      "cpu_cores": 1.0,
      "memory_bytes": 1073741824
    },
    "timeout": {
      "execution_timeout": "600s"
    }
  },
  "queued_by": "user"
}
EOF

# Enviar job
grpcurl -plaintext -d @ localhost:50051 hodei.JobExecutionService/QueueJob < /tmp/job_payload.json
```

### Verificaci√≥n del Resultado

```bash
# Ver todos los jobs
curl -s http://localhost:8080/api/jobs | jq

# Ver logs espec√≠ficos
just watch-logs

# O monitorear en la web
open http://localhost/jobs
```

**Salida esperada:**
- Clonado del repositorio ‚úÖ
- Instalaci√≥n de dependencias ‚úÖ
- Compilaci√≥n Maven ‚úÖ
- BUILD SUCCESS ‚úÖ

---

_¬øTienes preguntas? Abre un issue en el repositorio._
