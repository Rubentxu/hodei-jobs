# Gu√≠a de Usuario - Hodei Jobs Platform

**Versi√≥n**: 8.0
**√öltima Actualizaci√≥n**: 2025-12-16

Gu√≠a pr√°ctica para usuarios que quieren ejecutar jobs distribuidos usando la interfaz web de Hodei Jobs Platform.

## üìã √çndice

1. [Inicio R√°pido](#-inicio-r√°pido)
2. [Levantar la Aplicaci√≥n](#-levantar-la-aplicaci√≥n)
3. [Interfaz Web](#-interfaz-web)
   - [Dashboard](#dashboard)
   - [Crear un Job](#crear-un-job)
   - [Ver Detalles de un Job](#ver-detalles-de-un-job)
   - [Logs en Tiempo Real](#logs-en-tiempo-real)
   - [Historial de Jobs](#historial-de-jobs)
   - [Gesti√≥n de Providers](#gesti√≥n-de-providers)
   - [M√©tricas del Sistema](#m√©tricas-del-sistema)
4. [Ejemplos Pr√°cticos](#-ejemplos-pr√°cticos)
5. [Arquitectura del Sistema](#-arquitectura-del-sistema)
6. [Troubleshooting](#-troubleshooting)
7. [Referencia para Desarrolladores](#-referencia-para-desarrolladores)

---

## üöÄ Inicio R√°pido

En menos de 5 minutos puedes tener la plataforma funcionando y ejecutar tu primer job.

### Requisitos

- **Docker** y **Docker Compose** instalados
- Puerto `80` disponible (web)
- Puerto `50051` disponible (API gRPC)
- Puerto `5432` disponible (PostgreSQL)

### Pasos R√°pidos

```bash
# 1. Clonar el repositorio
git clone <repo-url>
cd hodei-jobs

# 2. Configurar variables de entorno
cat > .env << EOF
POSTGRES_PASSWORD=secure_password_here
EOF

# 3. Levantar toda la plataforma
docker compose -f docker-compose.prod.yml up -d

# 4. Abrir la interfaz web
open http://localhost  # macOS
xdg-open http://localhost  # Linux
```

¬°Listo! Ya puedes crear y ejecutar jobs desde la interfaz web.

## üê≥ Levantar la Aplicaci√≥n

### Opci√≥n 1: Producci√≥n (Recomendado)

Levanta toda la plataforma con un solo comando:

```bash
# Crear archivo de configuraci√≥n
cat > .env << EOF
POSTGRES_PASSWORD=tu-password-seguro
GRAFANA_PASSWORD=admin
EOF

# Levantar servicios principales
docker compose -f docker-compose.prod.yml up -d --build

# Ver logs
docker compose -f docker-compose.prod.yml logs -f

# Con monitoreo (Prometheus + Grafana)
docker compose -f docker-compose.prod.yml --profile monitoring up -d
```

**Servicios disponibles:**

| Servicio          | URL                   | Descripci√≥n           |
| ----------------- | --------------------- | --------------------- |
| **Web Dashboard** | http://localhost      | Interfaz principal    |
| **API gRPC**      | localhost:50051       | API para clientes     |
| **PostgreSQL**    | localhost:5432        | Base de datos         |
| **Prometheus**    | http://localhost:9090 | M√©tricas (opcional)   |
| **Grafana**       | http://localhost:3000 | Dashboards (opcional) |

### Opci√≥n 2: Desarrollo Local (Optimizado)

Hemos simplificado el flujo de desarrollo para que sea ultra-r√°pido.

```bash
# 1. Setup inicial (solo la primera vez)
./setup.sh

# 2. Iniciar entorno de desarrollo
./dev.sh
```

El script `./dev.sh` levantar√° autom√°ticamente:

- PostgreSQL (en Docker)
- Backend (con Hot Reload via Bacon)
- Frontend (con HMR via Vite)

Tambi√©n puedes usar comandos individuales si lo prefieres:

```bash
./dev.sh db       # Solo base de datos
./dev.sh backend  # Solo backend
./dev.sh frontend # Solo frontend
```

### Verificar que todo funciona

```bash
# Ver estado de los contenedores
docker compose -f docker-compose.prod.yml ps

# Verificar API gRPC
grpcurl -plaintext localhost:50051 list

# Abrir la web
open http://localhost
```

---

## üñ•Ô∏è Interfaz Web

La interfaz web est√° dise√±ada para ser intuitiva y m√≥vil-first. Aqu√≠ te explicamos cada secci√≥n.

### Dashboard

**URL:** `/` (p√°gina principal)

El dashboard muestra un resumen del estado del sistema:

- **Total Jobs**: N√∫mero total de jobs ejecutados
- **Running**: Jobs en ejecuci√≥n actualmente
- **Failed**: Jobs que fallaron
- **Success**: Jobs completados exitosamente
- **System Health**: Carga de CPU y estado de los nodos
- **Recent Executions**: √öltimos 5 jobs ejecutados

**Acciones r√°pidas:**

- Clic en el bot√≥n **+** (azul, esquina inferior derecha) para crear un nuevo job
- Clic en "See All" para ver el historial completo
- Clic en cualquier job reciente para ver sus detalles

---

### Crear un Job

**URL:** `/jobs/new`

Formulario completo para programar un nuevo job:

#### 1. Basic Info

- **Job Name**: Nombre descriptivo del job (ej: "Data Processing Pipeline")

#### 2. Core Execution

- **Command Type**: Tipo de comando a ejecutar
  - `Shell Command`: Comandos bash/shell
  - `Docker Exec`: Ejecutar dentro de un contenedor
  - `Python Script`: Script Python
  - `Node.js Script`: Script Node.js
- **Command / Script Content**: El comando o script a ejecutar

#### 3. Environment & Image

- **Container Image**: Imagen Docker a usar (ej: `ubuntu:latest`, `python:3.9`)
- **Environment Variables**: Variables de entorno (clave=valor)

#### 4. Resources

- **CPU Cores**: N√∫mero de cores (1-16)
- **Memory (MB)**: Memoria RAM en MB
- **Storage (MB)**: Almacenamiento temporal
- **Timeout (ms)**: Tiempo m√°ximo de ejecuci√≥n
- **GPU Required**: Activar si necesitas GPU
- **Architecture**: `x86_64` o `arm64`

#### 5. Preferences

- **Provider**: Seleccionar provider espec√≠fico o "Any"
- **Region**: Regi√≥n preferida o "Auto"
- **Job Priority**: `Low`, `Normal`, o `High`
- **Allow Retry**: Reintentar autom√°ticamente si falla

**Ejemplo r√°pido:**

```
Job Name: Hello World Test
Command Type: Shell Command
Script: echo "Hello from Hodei!" && date
Container Image: alpine:latest
CPU Cores: 1
Memory: 512
```

Clic en **"Schedule Job"** para encolar el job.

---

### Ver Detalles de un Job

**URL:** `/jobs/:jobId`

Muestra informaci√≥n detallada de un job espec√≠fico:

#### Pesta√±as disponibles:

**Overview:**

- **Timeline**: Progreso del job (Queued ‚Üí Image Pulled ‚Üí Running ‚Üí Cleanup)
- **Live Resources**: Uso de CPU y memoria en tiempo real
- **Latest Logs**: Vista previa de los √∫ltimos logs

**Config:**

- Comando ejecutado
- Imagen utilizada
- L√≠mites de CPU y memoria

**Logs:**

- Enlace al visor de logs completo

**Resources:**

- Gr√°ficos detallados de uso de recursos

#### Acciones:

- **SSH Access**: Acceso directo al worker (si est√° disponible)
- **Cancel Job**: Cancelar el job en ejecuci√≥n

---

### Logs en Tiempo Real

**URL:** `/jobs/:jobId/logs`

Visor de logs estilo terminal con streaming en tiempo real:

**Caracter√≠sticas:**

- **B√∫squeda**: Filtrar logs por texto (grep)
- **Filtros por nivel**: All, INFO, WARN, ERROR
- **Pause/Resume**: Pausar el streaming para analizar
- **Auto-scroll**: Seguir autom√°ticamente los nuevos logs

**Colores de logs:**

- üîµ **INFO**: Informaci√≥n general (azul)
- üü° **WARN**: Advertencias (amarillo)
- üî¥ **ERROR**: Errores (rojo)

**Controles:**

- **Pause/Resume**: Pausar o continuar el streaming
- **Clear**: Limpiar la pantalla
- **Scroll to bottom**: Ir al final de los logs

---

### Historial de Jobs

**URL:** `/jobs`

Lista completa de todos los jobs con:

- ID del job
- Nombre
- Estado (Running, Success, Failed)
- Tiempo de ejecuci√≥n
- Fecha de creaci√≥n

**Filtros disponibles:**

- Por estado
- Por fecha
- Por nombre

---

### Gesti√≥n de Providers

**URL:** `/providers`

Lista de providers de infraestructura disponibles:

| Provider        | Descripci√≥n                                   |
| --------------- | --------------------------------------------- |
| **Docker**      | Ejecuta jobs en contenedores Docker locales   |
| **Kubernetes**  | Ejecuta jobs como Pods en un cluster K8s      |
| **Firecracker** | Ejecuta jobs en microVMs (m√°ximo aislamiento) |

**Acciones:**

- Ver detalles de cada provider
- Habilitar/deshabilitar providers
- Configurar par√°metros espec√≠ficos

#### Crear nuevo Provider

**URL:** `/providers/new`

Formulario para agregar un nuevo provider con su configuraci√≥n espec√≠fica.

---

### M√©tricas del Sistema

**URL:** `/metrics`

Dashboard de m√©tricas del sistema:

- Jobs por estado
- Tiempo promedio de ejecuci√≥n
- Uso de recursos por provider
- Tendencias hist√≥ricas

---

## üìù Ejemplos Pr√°cticos

### Ejemplo 1: Job Simple (Echo)

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `Hello World`
   - **Command Type**: `Shell Command`
   - **Script**: `echo "Hello from Hodei!" && date`
   - **Container Image**: `alpine:latest`
3. Clic en **Schedule Job**
4. Ver el progreso en `/jobs/:jobId`

### Ejemplo 2: Script Python

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `Python Data Processing`
   - **Command Type**: `Python Script`
   - **Script**:
     ```python
     import sys
     print("Processing data...")
     for i in range(5):
         print(f"Step {i+1}/5 completed")
     print("Done!")
     ```
   - **Container Image**: `python:3.11-slim`
   - **Memory**: `1024`
3. Clic en **Schedule Job**

### Ejemplo 3: Job con Variables de Entorno

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `API Data Fetch`
   - **Command Type**: `Shell Command`
   - **Script**: `curl -H "Authorization: Bearer $API_TOKEN" $API_URL`
   - **Container Image**: `curlimages/curl:latest`
   - **Environment Variables**:
     - `API_TOKEN` = `tu-token-secreto`
     - `API_URL` = `https://api.example.com/data`
3. Clic en **Schedule Job**

### Ejemplo 4: Job de Larga Duraci√≥n

1. Ir a `/jobs/new`
2. Configurar:
   - **Job Name**: `Long Running Task`
   - **Command Type**: `Shell Command`
   - **Script**:
     ```bash
     for i in $(seq 1 60); do
       echo "[$(date)] Processing batch $i/60..."
       sleep 1
     done
     echo "All batches completed!"
     ```
   - **Container Image**: `alpine:latest`
   - **Timeout**: `120000` (2 minutos)
3. Clic en **Schedule Job**
4. Ir a `/jobs/:jobId/logs` para ver el progreso en tiempo real

---

## üîç Verificaci√≥n Avanzada (Eventos y Auditor√≠a)

Para asegurar que los jobs se est√°n ejecutando correctamente y generando los eventos de dominio esperados, puedes consultar directamente el sistema de auditor√≠a.

### Consultar Logs de Auditor√≠a (SQL)

Con√©ctate a la base de datos PostgreSQL corriendo en Docker.
_Nota: El usuario por defecto en desarrollo es `postgres`, en producci√≥n suele ser `hodei`._

```bash
# Opci√≥n A: Entorno Desarrollo
docker exec -it hodei-jobs-postgres psql -U postgres -d hodei

# Opci√≥n B: Entorno Producci√≥n (o Inicio R√°pido)
docker exec -it hodei-jobs-postgres psql -U hodei -d hodei

# Ejecutar query directa:
docker exec hodei-jobs-postgres psql -U hodei -d hodei -c "SELECT * FROM audit_logs LIMIT 5;"
```

### Consultas √ötiles

#### 1. Ver √∫ltimos eventos registrados

Verifica qu√© est√° pasando en el sistema en tiempo real.

```sql
SELECT occurred_at, event_type, actor, payload
FROM audit_logs
ORDER BY occurred_at DESC
LIMIT 10;
```

#### 2. Seguir el ciclo de vida de un Job espec√≠fico

Usando el `correlation_id` (que suele ser el Job ID para eventos de Job), puedes ver toda la historia de un job.

```sql
-- Reemplaza 'JOB_ID_AQUI' con el ID real de tu job
SELECT occurred_at, event_type, payload
FROM audit_logs
WHERE correlation_id = 'JOB_ID_AQUI'
ORDER BY occurred_at ASC;
```

> [!NOTE]
> Gracias a las mejoras recientes, **todos** los eventos del ciclo de vida (incluyendo √©xito/fallo) ahora incluyen el `correlation_id`, facilitando el seguimiento completo con esta √∫nica query.

### Verificaci√≥n del Ciclo de Vida (Orden de Eventos)

Para certificar que el flujo funciona correctamente, el orden cronol√≥gico de los eventos debe ser:

1.  **`JobCreated`**: El job entra al sistema (estado `Queued`).
2.  **`JobAssigned`**: El Scheduler asigna un worker.
3.  **`JobStatusChanged`** (Scheduled -> Running): El worker confirma el inicio de la ejecuci√≥n.
4.  **`JobStatusChanged`** (Running -> Succeeded/Failed): El worker reporta la finalizaci√≥n.

### Verificaci√≥n de Limpieza del Worker

Para verificar que el worker se libera correctamente tras finalizar el job, busca los eventos de latido (`WorkerHeartbeat`) o consulta el estado del worker. En entornos din√°micos (Docker), deber√≠as ver que el contenedor se detiene y elimina si la pol√≠tica de escalado as√≠ lo dicta.

**Verificar liberaci√≥n en logs del servidor:**

```bash
docker compose -f docker-compose.dev.yml logs api | grep "released"
```

### Verificaci√≥n de Logs de Ejecuci√≥n

Para confirmar que la salida del job (`stdout`/`stderr`) se transmite y registra correctamente:

1.  **Logs del Contenedor Worker** (si a√∫n existe):

    ```bash
    # Listar contenedores de workers (incluso detenidos)
    docker ps -a --filter "name=hodei-worker"

    # Ver logs espec√≠ficos
    docker logs <CONTAINER_ID>
    ```

2.  **Confirmar Recepci√≥n en el Servidor**:
    El servidor recibe los logs v√≠a gRPC y los registra (nivel DEBUG/INFO).
    ```bash
    docker logs hodei-jobs-api 2>&1 | grep "Log appended"
    ```

#### 3. Estad√≠sticas de Ejecuci√≥n

Cuenta cu√°ntos jobs han sido creados vs completados.

```sql
SELECT event_type, COUNT(*) as total
FROM audit_logs
GROUP BY event_type
ORDER BY total DESC;
```

### Verificaci√≥n de Integridad

Si un job parece "atascado", busca si falta alguno de los eventos intermedios. Por ejemplo, si ves `JobCreated` pero nunca `JobAssigned`, el problema est√° en el Scheduler o en la falta de recursos (Providers).

```sql
-- Buscar jobs hu√©rfanos (creados hace m√°s de 5 min sin asignar)
SELECT * FROM audit_logs
WHERE event_type = 'JobCreated'
AND occurred_at < NOW() - INTERVAL '5 minutes'
AND correlation_id NOT IN (
    SELECT correlation_id FROM audit_logs WHERE event_type = 'JobAssigned'
);
```

---

## üèóÔ∏è Arquitectura del Sistema

### Componentes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    HODEI JOBS PLATFORM                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Web UI    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ         gRPC Server (API)           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  (React)    ‚îÇ     ‚îÇ                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  ‚Ä¢ JobExecutionService              ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚Ä¢ WorkerAgentService               ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚Ä¢ SchedulerService                 ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚Ä¢ LogStreamService                 ‚îÇ   ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                     ‚îÇ                          ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                      ‚îÇ         Worker Providers            ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚îÇ Docker ‚îÇ ‚îÇ  K8s   ‚îÇ ‚îÇFirecracker‚îÇ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ   ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                             ‚îÇ          ‚îÇ           ‚îÇ          ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                      ‚îÇContainer‚îÇ ‚îÇ   Pod   ‚îÇ ‚îÇ  microVM  ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ Worker  ‚îÇ ‚îÇ Worker  ‚îÇ ‚îÇ  Worker   ‚îÇ   ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de un Job

1. **Usuario crea job** desde la web
2. **Job se encola** en PostgreSQL con estado `PENDING`
3. **Scheduler detecta** el job pendiente
4. **Provider aprovisiona** un worker (container/pod/microVM)
5. **Worker se registra** autom√°ticamente con OTP
6. **Job se despacha** al worker
7. **Worker ejecuta** el comando y env√≠a logs en tiempo real
8. **Job completa** y el resultado se guarda

### Estados del Job

| Estado      | Descripci√≥n                 |
| ----------- | --------------------------- |
| `PENDING`   | Esperando worker disponible |
| `ASSIGNED`  | Asignado a un worker        |
| `RUNNING`   | En ejecuci√≥n                |
| `SUCCEEDED` | Completado exitosamente     |
| `FAILED`    | Termin√≥ con error           |
| `CANCELLED` | Cancelado por el usuario    |
| `TIMEOUT`   | Excedi√≥ el tiempo l√≠mite    |

---

## üîß Troubleshooting

### La web no carga

```bash
# Verificar que los contenedores est√°n corriendo
docker compose -f docker-compose.prod.yml ps

# Ver logs del frontend
docker compose -f docker-compose.prod.yml logs web

# Reiniciar servicios
docker compose -f docker-compose.prod.yml restart
```

### Los jobs quedan en PENDING

```bash
# Verificar que hay providers habilitados
docker compose -f docker-compose.prod.yml logs api | grep -i provider

# Verificar Docker socket
docker ps

# Verificar logs del servidor
docker compose -f docker-compose.prod.yml logs api
```

### Error de conexi√≥n a PostgreSQL

```bash
# Verificar que PostgreSQL est√° corriendo
docker compose -f docker-compose.prod.yml logs postgres

# Verificar conectividad
docker exec hodei-jobs-postgres pg_isready -U postgres
```

### Los logs no aparecen en tiempo real

- Verificar que el job est√° en estado `RUNNING`
- Refrescar la p√°gina de logs
- Verificar la conexi√≥n WebSocket en las herramientas de desarrollo del navegador

### Limpiar y reiniciar todo

```bash
# Parar y eliminar todo
docker compose -f docker-compose.prod.yml down -v

# Reiniciar desde cero
docker compose -f docker-compose.prod.yml up -d
```

---

## üë®‚Äçüíª Referencia para Desarrolladores

Para informaci√≥n t√©cnica detallada sobre:

- Compilaci√≥n desde c√≥digo fuente
- Tests unitarios y de integraci√≥n
- API gRPC
- Desarrollo de nuevos providers

Consulta el archivo [DEVELOPMENT.md](./DEVELOPMENT.md) para la gu√≠a completa.

### Comandos √∫tiles (Justfile)

Usamos `just` para automatizar tareas comunes. Ejecuta `just --list` para ver todos los comandos disponibles.

```bash
# Desarrollo
just dev            # Inicia todo el entorno
just dev-db         # Inicia solo la base de datos
just dev-backend    # Inicia backend con hot reload

# Testing
just test           # Ejecuta todos los tests
just test-backend   # Tests de backend
just test-e2e       # Tests end-to-end

# Calidad de C√≥digo
just check          # Lint y format check
just clean          # Limpiar artefactos
```

### Variables de Entorno

| Variable               | Descripci√≥n                            | Default |
| ---------------------- | -------------------------------------- | ------- |
| `HODEI_DATABASE_URL`   | URL de PostgreSQL                      | -       |
| `HODEI_DEV_MODE`       | Modo desarrollo (acepta tokens dev-\*) | `0`     |
| `HODEI_DOCKER_ENABLED` | Habilitar Docker provider              | `0`     |
| `HODEI_K8S_ENABLED`    | Habilitar Kubernetes provider          | `0`     |
| `HODEI_FC_ENABLED`     | Habilitar Firecracker provider         | `0`     |
| `GRPC_PORT`            | Puerto del servidor gRPC               | `50051` |
| `RUST_LOG`             | Nivel de logs                          | `info`  |

---

## üìö Recursos Adicionales

- **README.md**: Descripci√≥n general del proyecto
- **README_ES.md**: README en espa√±ol
- **docker-compose.prod.yml**: Configuraci√≥n de producci√≥n
- **docker-compose.dev.yml**: Configuraci√≥n de desarrollo

---

_¬øTienes preguntas? Abre un issue en el repositorio._
