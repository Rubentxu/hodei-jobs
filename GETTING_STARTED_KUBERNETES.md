# Hodei Job Platform - GuÃ­a de Inicio: Kubernetes Provider

**VersiÃ³n**: 8.0  
**Ãšltima ActualizaciÃ³n**: 2025-12-18

Esta guÃ­a te ayudarÃ¡ a configurar y utilizar el **Kubernetes Provider** en Hodei Job Platform. Este provider permite aprovisionar Workers dinÃ¡micamente como Pods dentro de un clÃºster de Kubernetes.

## ðŸš€ Worker Agent v8.0 - HPC Ready en Kubernetes

El worker agent v8.0 incluye optimizaciones especÃ­ficas para entornos Kubernetes:

### Beneficios en Kubernetes

| OptimizaciÃ³n | Beneficio en K8s |
|--------------|------------------|
| **LogBatching** | 90-99% reducciÃ³n en calls gRPC desde el Pod |
| **CGroups Integration** | MÃ©tricas precisas desde cgroups del contenedor |
| **Cached Metrics** | Menor overhead en recolecciÃ³n de mÃ©tricas |
| **Zero-Copy I/O** | Menor uso de memoria en el Pod |
| **Async Cleanup** | Limpieza no bloqueante de recursos |
| **mTLS Ready** | Zero Trust security con certificados |

### Consideraciones de Rendimiento

**LogBatching en Kubernetes**:
- Los logs se agrupan en el Pod antes de enviarse
- Reduce la sobrecarga de red del clÃºster
- Mejor throughput para jobs con muchos logs

**MÃ©tricas con CGroups**:
- Lectura directa de cgroups del contenedor
- MÃ©tricas mÃ¡s precisas que `kubectl top`
- Cache TTL reduce la carga en cgroup filesystem

## ðŸ“‹ Prerrequisitos

Para utilizar este provider, necesitas:

1.  **ClÃºster de Kubernetes** accesible (Local o Remoto).
    - Recomendado para desarrollo: [Kind](https://kind.sigs.k8s.io/) o [Minikube](https://minikube.sigs.k8s.io/).
    - TambiÃ©n compatible con EKS, GKE, AKS, etc.
2.  **`kubectl`** instalado y configurado apuntando a tu clÃºster.
3.  **Permisos**: El contexto de Kubernetes debe tener permisos para crear `Namespaces`, `Pods`, `Services`, y `ServiceAccounts`.

## ðŸ³ ConstrucciÃ³n de la Imagen Worker

El provider de Kubernetes necesita que la imagen del worker (`hodei-jobs-worker`) contenga el binario del agente para poder comunicarse con el servidor. Debes construir esta imagen localmente.

1. **Construir la imagen:**

Desde la raÃ­z del proyecto:

```bash
docker build -f Dockerfile.worker -t hodei-jobs-worker:latest .
```

2. **Cargar la imagen en el clÃºster (Solo Desarrollo Local):**

Si usas **Kind** o **Minikube**, el clÃºster no verÃ¡ la imagen local a menos que la cargues explÃ­citamente:

- **Kind**:

  ```bash
  kind load docker-image hodei-jobs-worker:latest
  ```

- **Minikube**:
  ```bash
  minikube image load hodei-jobs-worker:latest
  ```

### ConfiguraciÃ³n BÃ¡sica (Tests E2E)

Para que los tests de integraciÃ³n funcionen (y para desarrollo local), el cÃ³digo espera encontrar un `ServiceAccount` llamado `hodei-jobs-worker` en el namespace `hodei-jobs-workers`.
El provider asigna esta cuenta a los Pods creados.

1. Crea el archivo `k8s/rbac.yaml` (o usa el existente) para crear este recurso:

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: hodei-jobs-worker
  namespace: hodei-jobs-workers
---
# Opcional: Rol para que el worker pueda inspeccionarse a sÃ­ mismo (si fuera necesario)
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: hodei-jobs-worker-role
  namespace: hodei-jobs-workers
rules:
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: hodei-jobs-worker-binding
  namespace: hodei-jobs-workers
subjects:
  - kind: ServiceAccount
    name: hodei-jobs-worker
    namespace: hodei-jobs-workers
roleRef:
  kind: Role
  name: hodei-jobs-worker-role
  apiGroup: rbac.authorization.k8s.io
```

2. Aplica la configuraciÃ³n:

```bash
kubectl apply -f k8s/rbac.yaml
```

### Despliegue de ProducciÃ³n

El directorio `deploy/kubernetes` contiene los manifiestos completos para un despliegue en clÃºster, incluyendo:

- `install.sh`: Script de instalaciÃ³n automatizada.
- `rbac.yaml`: Configura permisos para el Control Plane (`hodei-system`) sobre los Workers.
- `network-policy.yaml`: Aislamiento de red para los workers.

Estos manifiestos han sido actualizados para coincidir con los valores por defecto del cÃ³digo:

- Namespace: `hodei-jobs-workers`
- Service Account: `hodei-jobs-worker`

## âš™ï¸ ConfiguraciÃ³n del Servidor

AsegÃºrate de que tu entorno (donde corre `hodei-jobs-server`) tenga las siguientes variables configuradas o que el archivo `kubeconfig` estÃ© en la ubicaciÃ³n estÃ¡ndar (`~/.kube/config`).

```bash
# Opcional, por defecto usa ~/.kube/config
export KUBECONFIG=/path/to/your/kubeconfig

# Namespace donde se crearÃ¡n los workers (Default: hodei-jobs-workers)
export HODEI_K8S_NAMESPACE=hodei-jobs-workers
```

### Registrar el Provider

Si estÃ¡s corriendo el servidor localmente, debes registrar el provider de Kubernetes.

```bash
# Ejemplo usando cURL o la CLI (si estÃ¡ disponible)
curl -X POST http://localhost:8080/api/providers \
  -H "Content-Type: application/json" \
  -d '{
    "type": "kubernetes",
    "name": "k8s-local",
    "config": {
      "namespace": "hodei-jobs-workers",
      "image_pull_policy": "IfNotPresent"
    }
  }'
```

## ðŸš€ VerificaciÃ³n y Testing

Hodei Job Platform incluye una suite de tests E2E diseÃ±ada especÃ­ficamente para validar la integraciÃ³n con Kubernetes.

### Validar flujo E2E (Development)

Puedes ejecutar los tests de integraciÃ³n que verifican desde la conexiÃ³n con el clÃºster hasta el ciclo de vida de los Pods. Estos tests asumen la **OpciÃ³n A (Desarrollo Manual)** por defecto.

**Comando de verificaciÃ³n:**

```bash
# Habilita los tests de K8s y muestra la salida
HODEI_K8S_TEST=1 cargo test --test e2e_kubernetes_provider -- --ignored --nocapture
```

### Niveles de Test

La suite valida 4 niveles de integraciÃ³n:

1.  **Infraestructura Base**:

    - Verifica acceso a `kubectl`.
    - Verifica conexiÃ³n al clÃºster.
    - Crea el namespace de test si no existe.

2.  **Registro de Workers**:

    - Simula el registro de un worker (sin pod real) para probar la API.

3.  **Ciclo de Vida del Provider**:

    - **CreaciÃ³n**: El provider solicita crear un Pod.
    - **Estado**: Verifica que el Pod pasa a `Running`.
    - **Logs**: Intenta obtener logs del contenedor.
    - **DestrucciÃ³n**: Elimina el Pod y verifica su terminaciÃ³n.

4.  **Flujo Completo** (Opcional):
    - Requiere la imagen `hodei-jobs-worker` disponible en el clÃºster.

## ðŸ› ï¸ SoluciÃ³n de Problemas

### Error: `kubectl not available`

AsegÃºrate de que el binario `kubectl` estÃ¡ en el PATH de la mÃ¡quina donde corren los tests o el servidor.

### Error: `Kubernetes cluster not available`

Verifica tu conexiÃ³n:

```bash
kubectl cluster-info
```

### Error: `serviceaccount "hodei-jobs-worker" not found`

AsegÃºrate de haber aplicado el archivo `k8s/rbac.yaml` (OpciÃ³n A) o de haber configurado `HODEI_K8S_SERVICE_ACCOUNT` si usas la OpciÃ³n B.

### Pods en estado `ImagePullBackOff`

Si usas **Kind** o **Minikube**, es posible que el clÃºster no pueda ver tu imagen Docker local.

- **Kind**: `kind load docker-image hodei-jobs-worker:latest`
- **Minikube**: `minikube image load hodei-jobs-worker:latest`

O configura `image_pull_policy: "Always"` y usa una imagen de un registro pÃºblico.

## ðŸ” ConfiguraciÃ³n de mTLS en Kubernetes (v8.0)

Para habilitar Zero Trust security con mTLS:

### 1. Generar Certificados

```bash
# Desde el directorio del proyecto
./scripts/Worker\ Management/generate-certificates.sh
```

Esto crearÃ¡:
- `certs/ca.crt` - CA root certificate
- `certs/server.crt` - Server certificate
- `certs/server.key` - Server private key
- `certs/client.crt` - Client certificate (para workers)
- `certs/client.key` - Client private key

### 2. Crear Secrets en Kubernetes

```bash
# Crear secret para CA certificate
kubectl create secret generic hodei-ca-cert \
  --from-file=ca.crt=certs/ca.crt \
  --namespace=hodei-system

# Crear secret para client certificate (workers)
kubectl create secret generic hodei-client-cert \
  --from-file=client.crt=certs/client.crt \
  --from-file=client.key=certs/client.key \
  --namespace=hodei-jobs-workers
```

### 3. Configurar Variables de Entorno

En el Deployment del worker:

```yaml
env:
  - name: HODEI_MTLS_ENABLED
    value: "1"
  - name: HODEI_CLIENT_CERT_PATH
    value: "/etc/hodei/certs/client.crt"
  - name: HODEI_CLIENT_KEY_PATH
    value: "/etc/hodei/certs/client.key"
  - name: HODEI_CA_CERT_PATH
    value: "/etc/hodei/certs/ca.crt"
```

### 4. Montar Certificados

```yaml
volumeMounts:
  - name: client-cert
    mountPath: "/etc/hodei/certs"
    readOnly: true
  - name: ca-cert
    mountPath: "/etc/hodei/ca"
    readOnly: true

volumes:
  - name: client-cert
    secret:
      secretName: hodei-client-cert
  - name: ca-cert
    secret:
      secretName: hodei-ca-cert
      items:
        - key: ca.crt
          path: ca.crt
```

**Nota**: Requiere upgrade a `tonic >= 0.15` para habilitar TLS features.

## ðŸ“Š Monitoreo de Performance en Kubernetes

### Verificar LogBatching

```bash
# Ver logs del worker
kubectl logs -f deployment/hodei-worker -n hodei-jobs-workers

# Buscar indicadores de batching
grep -i "batch\|flush" /var/log/hodei/worker.log
```

### Verificar MÃ©tricas de CGroups

```bash
# Ejecutar en el worker pod
kubectl exec -it <worker-pod> -n hodei-jobs-workers -- bash

# Ver cgroup stats
cat /sys/fs/cgroup/memory/memory.usage_in_bytes
cat /sys/fs/cgroup/cpu/cpuacct.usage
```

### MÃ©tricas de Performance Esperadas

| MÃ©trica | Valor Esperado |
|---------|----------------|
| gRPC calls reduction | 90-99% |
| Memory allocation reduction | ~40% |
| Metrics collection overhead | ~60% reduction |
| Log throughput | > 10k logs/sec |
