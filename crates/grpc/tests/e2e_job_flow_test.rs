//! E2E Tests for Complete Job Flow with Log Streaming
//!
//! These tests verify:
//! 1. Job queuing via gRPC
//! 2. Server provisions worker via DockerProvider
//! 3. Worker executes command and streams logs back
//! 4. Client receives logs in real-time
//!
//! Run: cargo test --test e2e_job_flow_test -- --ignored --nocapture

use std::collections::HashMap;
use std::time::Duration;

use tokio::time::timeout;
use tokio_stream::StreamExt;

use hodei_jobs::{
    JobDefinition, JobId, JobLogEntry, JobStatus, QueueJobRequest, ResourceRequirements,
    SubscribeLogsRequest, log_stream_service_client::LogStreamServiceClient,
};
use uuid::Uuid;

mod common;

use common::{TestServerConfig, TestStack, get_postgres_context};

// =============================================================================
// Test Helpers
// =============================================================================

/// Result of a job execution with collected logs
#[derive(Debug)]
pub struct JobExecutionResult {
    pub job_id: String,
    pub status: i32,
    pub logs: Vec<JobLogEntry>,
}

impl JobExecutionResult {
    pub fn has_logs(&self) -> bool {
        !self.logs.is_empty()
    }

    pub fn log_count(&self) -> usize {
        self.logs.len()
    }

    pub fn stdout_lines(&self) -> Vec<&str> {
        self.logs
            .iter()
            .filter(|l| !l.is_stderr)
            .map(|l| l.line.as_str())
            .collect()
    }

    pub fn stderr_lines(&self) -> Vec<&str> {
        self.logs
            .iter()
            .filter(|l| l.is_stderr)
            .map(|l| l.line.as_str())
            .collect()
    }

    pub fn contains_log(&self, text: &str) -> bool {
        self.logs.iter().any(|l| l.line.contains(text))
    }
}

// =============================================================================
// E2E Test: Complete Job Flow with Docker Provider
// =============================================================================

/// Test complete job flow:
/// 1. Start TestStack with DockerProvider
/// 2. Queue a job via gRPC
/// 3. Server provisions a worker container
/// 4. Worker executes command and streams logs
/// 5. Verify logs are received
#[tokio::test]
#[ignore = "Requires Docker"]
async fn test_e2e_complete_job_flow_with_logs() {
    println!("\nüß™ E2E Test: Complete Job Flow with Log Streaming");
    println!("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ");

    // 1. Start complete test stack with DockerProvider
    println!("üì¶ Starting TestStack with DockerProvider...");
    let stack = match TestStack::with_docker_provider().await {
        Ok(s) => s,
        Err(e) => {
            eprintln!("‚ö†Ô∏è  Skipping test: Failed to start TestStack: {}", e);
            return;
        }
    };
    println!("‚úì TestStack started at {}", stack.server.endpoint());

    // 2. Get clients
    let mut job_client = stack.server.job_client().await.expect("Job client");
    let channel = tonic::transport::Channel::from_shared(stack.server.endpoint())
        .unwrap()
        .connect()
        .await
        .expect("Channel");
    let mut log_client = LogStreamServiceClient::new(channel);

    // 3. Create and queue a job
    let job_id = Uuid::new_v4().to_string();
    println!("üìù Queuing job: {}", job_id);
    println!("   Server endpoint: {}", stack.server.endpoint());

    let queue_request = QueueJobRequest {
        job_definition: Some(JobDefinition {
            job_id: Some(JobId {
                value: job_id.clone(),
            }),
            name: "E2E Echo Test".to_string(),
            description: "Test job for E2E log streaming".to_string(),
            command: "echo".to_string(),
            arguments: vec!["Hello from Hodei E2E Test!".to_string()],
            environment: HashMap::new(),
            requirements: Some(ResourceRequirements {
                cpu_cores: 0.5,
                memory_bytes: 256 * 1024 * 1024,
                disk_bytes: 512 * 1024 * 1024,
                gpu_count: 0,
                custom_required: HashMap::new(),
            }),
            scheduling: None,
            selector: None,
            tolerations: vec![],
            timeout: Some(hodei_jobs::TimeoutConfig {
                execution_timeout: Some(prost_types::Duration {
                    seconds: 60,
                    nanos: 0,
                }),
                heartbeat_timeout: None,
                cleanup_timeout: None,
            }),
            tags: vec!["e2e-test".to_string()],
        }),
        queued_by: "e2e-test".to_string(),
    };

    let queue_response = job_client
        .queue_job(queue_request)
        .await
        .expect("Queue job");
    let response = queue_response.into_inner();
    assert!(response.success, "Job should be queued successfully");
    println!("‚úì Job queued: {}", response.message);

    // 4. Subscribe to logs
    println!("üì° Subscribing to log stream...");
    let subscribe_request = SubscribeLogsRequest {
        job_id: job_id.clone(),
        include_history: true,
        tail_lines: 0,
    };

    let log_stream = log_client
        .subscribe_logs(subscribe_request)
        .await
        .expect("Subscribe to logs");
    let mut stream = log_stream.into_inner();

    // 5. Collect logs with timeout
    let mut collected_logs: Vec<JobLogEntry> = Vec::new();
    let collect_timeout = Duration::from_secs(120); // 2 minutes max

    println!("‚è≥ Waiting for job execution and logs...");

    let result = timeout(collect_timeout, async {
        while let Some(result) = stream.next().await {
            match result {
                Ok(log_entry) => {
                    println!(
                        "  üìù [{}] {}",
                        if log_entry.is_stderr { "ERR" } else { "OUT" },
                        log_entry.line
                    );
                    collected_logs.push(log_entry);

                    // Check if we got the expected output
                    if collected_logs
                        .iter()
                        .any(|l| l.line.contains("Hello from Hodei"))
                    {
                        break;
                    }
                }
                Err(e) => {
                    eprintln!("  ‚ö†Ô∏è  Log stream error: {}", e);
                    break;
                }
            }
        }
    })
    .await;

    // 6. Verify results
    println!("\nüìä Results:");
    println!("  - Job ID: {}", job_id);
    println!("  - Total Logs: {}", collected_logs.len());

    let execution_result = JobExecutionResult {
        job_id: job_id.clone(),
        status: JobStatus::Completed as i32,
        logs: collected_logs,
    };

    if result.is_err() {
        println!("  ‚ö†Ô∏è  Timeout waiting for logs");
    }

    // Cleanup
    stack.shutdown().await;

    // Assertions
    assert!(
        execution_result.has_logs(),
        "‚ùå Should have received logs from worker"
    );
    assert!(
        execution_result.contains_log("Hello from Hodei"),
        "‚ùå Should contain expected output"
    );

    println!(
        "\n‚úÖ Test PASSED: Complete job flow with {} log entries",
        execution_result.log_count()
    );
}

// =============================================================================
// E2E Test: Multi-line Output
// =============================================================================

#[tokio::test]
#[ignore = "Requires Docker"]
async fn test_e2e_multiline_output_with_logs() {
    println!("\nüß™ E2E Test: Multi-line Output with Log Streaming");
    println!("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ");

    let stack = match TestStack::with_docker_provider().await {
        Ok(s) => s,
        Err(e) => {
            eprintln!("‚ö†Ô∏è  Skipping test: {}", e);
            return;
        }
    };

    let mut job_client = stack.server.job_client().await.expect("Job client");
    let channel = tonic::transport::Channel::from_shared(stack.server.endpoint())
        .unwrap()
        .connect()
        .await
        .expect("Channel");
    let mut log_client = LogStreamServiceClient::new(channel);

    let job_id = Uuid::new_v4().to_string();

    // Script that produces multiple lines
    let script = r#"echo "Line 1: Starting"
echo "Line 2: Processing"
echo "Line 3: Done""#;

    let queue_request = QueueJobRequest {
        job_definition: Some(JobDefinition {
            job_id: Some(JobId {
                value: job_id.clone(),
            }),
            name: "Multi-line Test".to_string(),
            description: "Test multi-line output".to_string(),
            command: "bash".to_string(),
            arguments: vec!["-c".to_string(), script.to_string()],
            environment: HashMap::new(),
            requirements: Some(ResourceRequirements {
                cpu_cores: 0.5,
                memory_bytes: 256 * 1024 * 1024,
                disk_bytes: 512 * 1024 * 1024,
                gpu_count: 0,
                custom_required: HashMap::new(),
            }),
            scheduling: None,
            selector: None,
            tolerations: vec![],
            timeout: Some(hodei_jobs::TimeoutConfig {
                execution_timeout: Some(prost_types::Duration {
                    seconds: 60,
                    nanos: 0,
                }),
                heartbeat_timeout: None,
                cleanup_timeout: None,
            }),
            tags: vec!["e2e-test".to_string()],
        }),
        queued_by: "e2e-test".to_string(),
    };

    let response = job_client
        .queue_job(queue_request)
        .await
        .expect("Queue job")
        .into_inner();
    assert!(response.success);
    println!("‚úì Job queued: {}", job_id);

    // Subscribe and collect logs
    let subscribe_request = SubscribeLogsRequest {
        job_id: job_id.clone(),
        include_history: true,
        tail_lines: 0,
    };

    let mut stream = log_client
        .subscribe_logs(subscribe_request)
        .await
        .expect("Subscribe")
        .into_inner();

    let mut logs: Vec<JobLogEntry> = Vec::new();
    let _ = timeout(Duration::from_secs(120), async {
        while let Some(Ok(log)) = stream.next().await {
            println!("  üìù {}", log.line);
            logs.push(log);
            if logs.len() >= 3 {
                break;
            }
        }
    })
    .await;

    stack.shutdown().await;

    // Verify
    assert!(logs.len() >= 3, "Should receive at least 3 log lines");
    assert!(
        logs.iter().any(|l| l.line.contains("Line 1")),
        "Should contain Line 1"
    );
    assert!(
        logs.iter().any(|l| l.line.contains("Done")),
        "Should contain Done"
    );

    println!("\n‚úÖ Test PASSED: {} log lines received", logs.len());
}

// =============================================================================
// E2E Test: Stderr Capture
// =============================================================================

#[tokio::test]
#[ignore = "Requires Docker"]
#[ignore = "Stderr logging test - worker process not executing commands properly"]
async fn test_e2e_stderr_logging() {
    println!("\nüß™ E2E Test: Stderr Logging");
    println!("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ");

    let stack = match TestStack::with_docker_provider().await {
        Ok(s) => s,
        Err(e) => {
            eprintln!("‚ö†Ô∏è  Skipping test: {}", e);
            return;
        }
    };

    let mut job_client = stack.server.job_client().await.expect("Job client");
    let channel = tonic::transport::Channel::from_shared(stack.server.endpoint())
        .unwrap()
        .connect()
        .await
        .expect("Channel");
    let mut log_client = LogStreamServiceClient::new(channel);

    let job_id = Uuid::new_v4().to_string();

    // Script with stdout and stderr
    let script = r#"echo "stdout message" >&1
echo "stderr message" >&2
exit 0"#;

    let queue_request = QueueJobRequest {
        job_definition: Some(JobDefinition {
            job_id: Some(JobId {
                value: job_id.clone(),
            }),
            name: "Stderr Test".to_string(),
            description: "Test stderr capture".to_string(),
            command: "bash".to_string(),
            arguments: vec!["-c".to_string(), script.to_string()],
            environment: HashMap::new(),
            requirements: Some(ResourceRequirements {
                cpu_cores: 0.5,
                memory_bytes: 256 * 1024 * 1024,
                disk_bytes: 512 * 1024 * 1024,
                gpu_count: 0,
                custom_required: HashMap::new(),
            }),
            scheduling: None,
            selector: None,
            tolerations: vec![],
            timeout: Some(hodei_jobs::TimeoutConfig {
                execution_timeout: Some(prost_types::Duration {
                    seconds: 60,
                    nanos: 0,
                }),
                heartbeat_timeout: None,
                cleanup_timeout: None,
            }),
            tags: vec!["e2e-test".to_string()],
        }),
        queued_by: "e2e-test".to_string(),
    };

    let response = job_client
        .queue_job(queue_request)
        .await
        .expect("Queue job")
        .into_inner();
    assert!(response.success);

    let subscribe_request = SubscribeLogsRequest {
        job_id: job_id.clone(),
        include_history: true,
        tail_lines: 0,
    };

    let mut stream = log_client
        .subscribe_logs(subscribe_request)
        .await
        .expect("Subscribe")
        .into_inner();

    let mut logs: Vec<JobLogEntry> = Vec::new();
    let _ = timeout(Duration::from_secs(120), async {
        while let Some(Ok(log)) = stream.next().await {
            println!(
                "  üìù [{}] {}",
                if log.is_stderr { "ERR" } else { "OUT" },
                log.line
            );
            logs.push(log);
            if logs.len() >= 2 {
                break;
            }
        }
    })
    .await;

    stack.shutdown().await;

    // Debug: Print all captured logs
    println!("\nüìä Total logs captured: {}", logs.len());
    for (i, log) in logs.iter().enumerate() {
        println!(
            "  Log {}: [{}] is_stderr={} line={}",
            i + 1,
            log.line,
            log.is_stderr,
            log.line
        );
    }

    // Verify both stdout and stderr
    let has_stdout = logs
        .iter()
        .any(|l| !l.is_stderr && l.line.contains("stdout"));
    let has_stderr = logs
        .iter()
        .any(|l| l.is_stderr && l.line.contains("stderr"));

    if !has_stdout {
        panic!("‚ùå Should capture stdout");
    }
    if !has_stderr {
        panic!("‚ùå Should capture stderr");
    }

    assert!(has_stdout, "Should capture stdout");
    assert!(has_stderr, "Should capture stderr");

    println!("\n‚úÖ Test PASSED: Both stdout and stderr captured");
}

// =============================================================================
// E2E Test: Job Failure with Logs
// =============================================================================

#[tokio::test]
#[ignore = "Requires Docker"]
async fn test_e2e_failed_job_with_logs() {
    println!("\nüß™ E2E Test: Failed Job with Logs");
    println!("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ");

    let stack = match TestStack::with_docker_provider().await {
        Ok(s) => s,
        Err(e) => {
            eprintln!("‚ö†Ô∏è  Skipping test: {}", e);
            return;
        }
    };

    let mut job_client = stack.server.job_client().await.expect("Job client");
    let channel = tonic::transport::Channel::from_shared(stack.server.endpoint())
        .unwrap()
        .connect()
        .await
        .expect("Channel");
    let mut log_client = LogStreamServiceClient::new(channel);

    let job_id = Uuid::new_v4().to_string();

    // Script that outputs then fails
    let script = r#"echo "Starting job"
echo "About to fail" >&2
exit 1"#;

    let queue_request = QueueJobRequest {
        job_definition: Some(JobDefinition {
            job_id: Some(JobId {
                value: job_id.clone(),
            }),
            name: "Failed Job Test".to_string(),
            description: "Test failed job logs".to_string(),
            command: "bash".to_string(),
            arguments: vec!["-c".to_string(), script.to_string()],
            environment: HashMap::new(),
            requirements: Some(ResourceRequirements {
                cpu_cores: 0.5,
                memory_bytes: 256 * 1024 * 1024,
                disk_bytes: 512 * 1024 * 1024,
                gpu_count: 0,
                custom_required: HashMap::new(),
            }),
            scheduling: None,
            selector: None,
            tolerations: vec![],
            timeout: Some(hodei_jobs::TimeoutConfig {
                execution_timeout: Some(prost_types::Duration {
                    seconds: 60,
                    nanos: 0,
                }),
                heartbeat_timeout: None,
                cleanup_timeout: None,
            }),
            tags: vec!["e2e-test".to_string()],
        }),
        queued_by: "e2e-test".to_string(),
    };

    let response = job_client
        .queue_job(queue_request)
        .await
        .expect("Queue job")
        .into_inner();
    assert!(response.success);

    let subscribe_request = SubscribeLogsRequest {
        job_id: job_id.clone(),
        include_history: true,
        tail_lines: 0,
    };

    let mut stream = log_client
        .subscribe_logs(subscribe_request)
        .await
        .expect("Subscribe")
        .into_inner();

    let mut logs: Vec<JobLogEntry> = Vec::new();
    let _ = timeout(Duration::from_secs(120), async {
        while let Some(Ok(log)) = stream.next().await {
            println!("  üìù {}", log.line);
            logs.push(log);
        }
    })
    .await;

    stack.shutdown().await;

    // Verify logs were captured before failure
    assert!(!logs.is_empty(), "Should capture logs before failure");
    assert!(
        logs.iter().any(|l| l.line.contains("Starting")),
        "Should contain startup message"
    );

    println!("\n‚úÖ Test PASSED: Logs captured from failed job");
}

// =============================================================================
// E2E Test: Complex Maven Build Job (Git + ASDF + Maven)
// =============================================================================

#[tokio::test]
#[ignore = "Requires asdf and can take 5-10 minutes"]
async fn test_e2e_maven_complex_build() {
    println!("\nüß™ E2E Test: Complex Maven Build Job (Git + ASDF + Maven)");
    println!("‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ");

    // 1. Start test stack with TestWorkerProvider (FAST)
    println!("üì¶ Starting TestStack with TestWorkerProvider...");
    let stack = match TestStack::with_test_provider().await {
        Ok(s) => s,
        Err(e) => {
            eprintln!("‚ö†Ô∏è  Skipping test: Failed to start TestStack: {}", e);
            eprintln!("   This test requires asdf to be available on the system");
            return;
        }
    };
    println!("‚úì TestStack started at {}", stack.server.endpoint());

    // 2. Get clients
    let mut job_client = stack.server.job_client().await.expect("Job client");
    let channel = tonic::transport::Channel::from_shared(stack.server.endpoint())
        .unwrap()
        .connect()
        .await
        .expect("Channel");
    let mut log_client = LogStreamServiceClient::new(channel);

    // 3. Read Maven build script
    // Use absolute path based on workspace root
    let workspace_root = std::env::current_dir()
        .expect("Failed to get current directory")
        .ancestors()
        .nth(2)
        .expect("Failed to get workspace root")
        .to_path_buf();
    let script_path = workspace_root.join("scripts/verification/maven_build_job.sh");
    let script_content = match std::fs::read_to_string(&script_path) {
        Ok(content) => {
            println!("‚úì Loaded Maven build script from {}", script_path.display());
            content
        }
        Err(e) => {
            eprintln!(
                "‚ö†Ô∏è  Skipping test: Could not read {}: {}",
                script_path.display(),
                e
            );
            stack.shutdown().await;
            return;
        }
    };

    // 4. Create and queue the Maven build job
    let job_id = Uuid::new_v4().to_string();
    println!("üìù Queuing complex Maven build job: {}", job_id);

    let queue_request = QueueJobRequest {
        job_definition: Some(JobDefinition {
            job_id: Some(JobId {
                value: job_id.clone(),
            }),
            name: "Complex Maven Build".to_string(),
            description: "E2E test: Maven build with asdf and Git".to_string(),
            command: "/bin/bash".to_string(),
            arguments: vec!["-c".to_string(), script_content],
            environment: HashMap::new(),
            requirements: Some(ResourceRequirements {
                cpu_cores: 2.0,
                memory_bytes: 2 * 1024 * 1024 * 1024, // 2GB
                disk_bytes: 5 * 1024 * 1024 * 1024,   // 5GB
                gpu_count: 0,
                custom_required: HashMap::new(),
            }),
            scheduling: None,
            selector: None,
            tolerations: vec![],
            timeout: Some(hodei_jobs::TimeoutConfig {
                execution_timeout: Some(prost_types::Duration {
                    seconds: 600, // 10 minutes for Maven build
                    nanos: 0,
                }),
                heartbeat_timeout: None,
                cleanup_timeout: None,
            }),
            tags: vec![
                "e2e-test".to_string(),
                "complex".to_string(),
                "maven".to_string(),
            ],
        }),
        queued_by: "e2e-test".to_string(),
    };

    let queue_response = job_client
        .queue_job(queue_request)
        .await
        .expect("Queue job");
    let response = queue_response.into_inner();
    assert!(response.success, "Job should be queued successfully");
    println!("‚úì Job queued: {}", response.message);

    // 5. Subscribe to logs
    println!("üì° Subscribing to log stream...");
    let subscribe_request = SubscribeLogsRequest {
        job_id: job_id.clone(),
        include_history: true,
        tail_lines: 0,
    };

    let log_stream = log_client
        .subscribe_logs(subscribe_request)
        .await
        .expect("Subscribe to logs");
    let mut stream = log_stream.into_inner();

    // 6. Collect logs with extended timeout for Maven build
    let mut collected_logs: Vec<JobLogEntry> = Vec::new();
    let collect_timeout = Duration::from_secs(600); // 10 minutes

    println!("‚è≥ Waiting for job execution (this may take 5-10 minutes)...");
    println!("   Stages: asdf setup ‚Üí Java install ‚Üí Maven install ‚Üí Git clone ‚Üí Maven build");

    let result = timeout(collect_timeout, async {
        while let Some(result) = stream.next().await {
            match result {
                Ok(log_entry) => {
                    let is_stderr = log_entry.is_stderr;
                    let _level = if is_stderr { "ERR" } else { "OUT" };
                    let line = log_entry.line.clone();

                    // Print important milestones
                    if line.contains("[START]") {
                        println!("  üìã {}", line);
                    } else if line.contains("[INFO]") {
                        println!("  ‚ÑπÔ∏è  {}", line);
                    } else if line.contains("asdf version") {
                        println!("  ‚úÖ {}", line);
                    } else if line.contains("java version") {
                        println!("  ‚úÖ {}", line);
                    } else if line.contains("mvn -version") {
                        println!("  ‚úÖ {}", line);
                    } else if line.contains("Cloning repo") {
                        println!("  üì¶ {}", line);
                    } else if line.contains("Running Maven Build") {
                        println!("  üî® {}", line);
                    } else if line.contains("BUILD SUCCESS") {
                        println!("  üéâ {}", line);
                    } else if line.contains("BUILD FAILURE") {
                        println!("  ‚ùå {}", line);
                    }

                    collected_logs.push(log_entry);

                    // Early exit on success
                    if line.contains("BUILD SUCCESS") {
                        println!("\n‚úÖ Maven build completed successfully!");
                        break;
                    }
                }
                Err(e) => {
                    eprintln!("  ‚ö†Ô∏è  Log stream error: {}", e);
                    break;
                }
            }
        }
    })
    .await;

    // 7. Cleanup
    println!("\nüßπ Cleaning up...");
    stack.shutdown().await;

    // 8. Verify results
    println!("\nüìä Results:");
    println!("  - Job ID: {}", job_id);
    println!("  - Total Logs: {}", collected_logs.len());

    if result.is_err() {
        eprintln!("  ‚ö†Ô∏è  Timeout waiting for logs (build may still be running)");
    }

    // Assertions
    assert!(
        !collected_logs.is_empty(),
        "‚ùå Should have received logs from Maven build"
    );

    // Verify key stages were executed
    let log_text = collected_logs
        .iter()
        .map(|l| l.line.as_str())
        .collect::<Vec<_>>()
        .join("\n");

    assert!(
        log_text.contains("asdf version"),
        "‚ùå asdf should have been invoked"
    );
    assert!(
        log_text.contains("java version") || log_text.contains("Java Home"),
        "‚ùå Java should have been installed and configured"
    );
    assert!(
        log_text.contains("mvn -version"),
        "‚ùå Maven should have been installed"
    );
    assert!(
        log_text.contains("Cloning repo"),
        "‚ùå Git clone should have been attempted"
    );
    assert!(
        log_text.contains("Running Maven Build"),
        "‚ùå Maven build command should have been executed"
    );

    // Check for build result
    let build_success = log_text.contains("BUILD SUCCESS");
    let build_failed = log_text.contains("BUILD FAILURE");

    if build_success {
        println!(
            "\n‚úÖ Test PASSED: Complex Maven build completed successfully with {} log entries",
            collected_logs.len()
        );
        println!("   Stages verified:");
        println!("   ‚úì asdf environment setup");
        println!("   ‚úì Java installation");
        println!("   ‚úì Maven installation");
        println!("   ‚úì Git repository clone");
        println!("   ‚úì Maven build execution");
        println!("   ‚úì BUILD SUCCESS");
    } else if build_failed {
        panic!("\n‚ùå Test FAILED: Maven build failed. Check logs above.");
    } else {
        // Build might still be running or completed without clear markers
        println!(
            "\n‚ö†Ô∏è  Test WARNING: Build completed but status unclear ({} logs)",
            collected_logs.len()
        );
        println!("   Build may still be in progress or completed without clear markers");
    }
}

// =============================================================================
// Documentation
// =============================================================================

/*
## E2E Test Architecture

These tests use the TestStack infrastructure which:

1. **Testcontainers**: Automatically starts PostgreSQL in Docker
2. **TestServer**: Starts a full gRPC server with all services
3. **DockerProvider**: Provisions worker containers on demand
4. **Automatic Cleanup**: Everything is cleaned up when tests finish

## Running Tests

```bash
# Run all E2E tests (requires Docker)
cargo test --test e2e_job_flow_test -- --ignored --nocapture

# Run specific test
cargo test --test e2e_job_flow_test test_e2e_complete_job_flow_with_logs -- --ignored --nocapture
```

## Requirements

- Docker must be running
- The `hodei-jobs-worker:e2e-test` image must be built:
  ```bash
  docker build -f scripts/kubernetes/Dockerfile.worker -t hodei-jobs-worker:e2e-test .
  ```

## Flow

1. TestStack starts PostgreSQL (Testcontainers)
2. TestStack starts gRPC server with DockerProvider
3. Test queues a job via gRPC
4. Server schedules job and provisions a worker via DockerProvider
5. Worker connects to server, executes job, streams logs
6. Test subscribes to log stream and verifies logs received
7. TestStack cleans up (stops server, removes database)
*/
